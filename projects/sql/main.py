import streamlit as st
import os
import json
import pandas as pd
from dotenv import load_dotenv
from sqlalchemy import create_engine, text, inspect
from openai import OpenAI
import tempfile

# -----------------------------
# åˆå§‹åŒ–
# -----------------------------
load_dotenv()

def get_ai_client():
    api_key = os.getenv("DASHSCOPE_API_KEY")
    base_url = os.getenv("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1 ").strip()
    if not api_key:
        st.error("âŒ è¯·åœ¨ .env ä¸­è®¾ç½® DASHSCOPE_API_KEY")
        st.stop()
    return OpenAI(api_key=api_key, base_url=base_url)

# -----------------------------
# æ•°æ®åº“è¿æ¥ç®¡ç†
# -----------------------------
DB_TYPES = {
    "PostgreSQL": "postgresql",
    "MySQL": "mysql",
    "SQLite": "sqlite",
    "Oracle": "oracle"
}

def build_connection_string(db_type, config):
    if db_type == "postgresql":
        return f"postgresql://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}"
    elif db_type == "mysql":
        return f"mysql+pymysql://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}"
    elif db_type == "sqlite":
        return f"sqlite:///{config['file_path']}"
    elif db_type == "oracle":
        return f"oracle+cx_oracle://{config['user']}:{config['password']}@{config['host']}:{config['port']}/?service_name={config['service_name']}"
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹")

def test_database_connection(db_type, config):
    try:
        if db_type == "sqlite":
            if "file_path" not in config:
                return False, "è¯·ä¸Šä¼  SQLite æ–‡ä»¶"
            url = build_connection_string(db_type, config)
            engine = create_engine(url)
            with engine.connect() as conn:
                conn.execute(text("SELECT sqlite_version()"))
            return True, "âœ… SQLite è¿æ¥æˆåŠŸ"
        else:
            url = build_connection_string(db_type, config)
            engine = create_engine(url)
            with engine.connect() as conn:
                if db_type == "postgresql":
                    conn.execute(text("SELECT version()"))
                elif db_type == "mysql":
                    conn.execute(text("SELECT VERSION()"))
                elif db_type == "oracle":
                    conn.execute(text("SELECT * FROM v$version WHERE rownum = 1"))
            return True, "âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ"
    except Exception as e:
        return False, f"âŒ è¿æ¥å¤±è´¥: {str(e)}"

def get_db_schema(db_type, config):
    try:
        url = build_connection_string(db_type, config)
        engine = create_engine(url)
        inspector = inspect(engine)
        schema = {}
        for table in inspector.get_table_names():
            cols = inspector.get_columns(table)
            schema[table] = [
                {"column": col["name"], "type": str(col["type"])}
                for col in cols
            ]
        return schema
    except Exception as e:
        st.error(f"è·å– schema å¤±è´¥: {e}")
        return {}

def execute_safe_query(db_type, config, sql):
    if not sql.strip().lower().startswith("select"):
        return None, "âŒ ä»…å…è®¸ SELECT æŸ¥è¯¢"
    dangerous = ["drop", "delete", "update", "insert", "alter", "create", "truncate"]
    if any(kw in sql.lower() for kw in dangerous):
        return None, "âŒ æ£€æµ‹åˆ°å±é™©æ“ä½œ"

    try:
        url = build_connection_string(db_type, config)
        engine = create_engine(url)
        with engine.connect() as conn:
            df = pd.read_sql(text(sql), conn)
        return df, None
    except Exception as e:
        return None, f"SQL æ‰§è¡Œé”™è¯¯: {str(e)}"

# -----------------------------
# AI åŠ©æ‰‹ï¼šä¸¤é˜¶æ®µ
# -----------------------------
def ask_ai_generate_sql(user_question: str, schema_info: dict):
    client = get_ai_client()
    tools = [{
        "type": "function",
        "function": {
            "name": "execute_sql_query",
            "description": "ç”Ÿæˆå®‰å…¨çš„ SELECT æŸ¥è¯¢",
            "parameters": {
                "type": "object",
                "properties": {
                    "sql": {"type": "string"},
                    "explanation": {"type": "string"}
                },
                "required": ["sql", "explanation"]
            }
        }
    }]

    system_prompt = f"""
æ•°æ®åº“ä¸­åŒ…å«ä»¥ä¸‹è¡¨ï¼ˆåç§°åŒºåˆ†å¤§å°å†™ï¼‰ï¼š
{', '.join(schema_info.keys())}

å®Œæ•´ç»“æ„ï¼š
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

ä½ å¿…é¡»è°ƒç”¨ execute_sql_query å‡½æ•°ã€‚
è§„åˆ™ï¼š
- åªç”Ÿæˆ SELECT
- è¡¨åå’Œå­—æ®µå¿…é¡»å­˜åœ¨
- ç”¨ä¸­æ–‡å†™ explanation
"""

    response = client.chat.completions.create(
        model="qwen-plus",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_question}
        ],
        tools=tools,
        tool_choice={"type": "function", "function": {"name": "execute_sql_query"}},
        temperature=0.1
    )

    tool_calls = response.choices[0].message.tool_calls
    if not tool_calls:
        return {"error": "æ¨¡å‹æœªè°ƒç”¨å‡½æ•°"}

    try:
        args = json.loads(tool_calls[0].function.arguments)
        sql = args.get("sql", "").strip()
        explanation = args.get("explanation", "").strip()
        if not sql:
            return {"error": "SQL ä¸ºç©º"}
        return {"sql": sql, "explanation": explanation}
    except Exception as e:
        return {"error": f"è§£æå¤±è´¥: {e}"}

def generate_natural_answer(user_question: str, sql: str, result_df: pd.DataFrame):
    client = get_ai_client()
    
    if result_df.empty:
        result_text = "æŸ¥è¯¢è¿”å›ç©ºç»“æœã€‚"
    else:
        sample = result_df.head(10)
        result_text = sample.to_string(index=False)

    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·çš„åŸå§‹é—®é¢˜ã€æ‰§è¡Œçš„ SQL å’ŒæŸ¥è¯¢ç»“æœï¼Œç”¨ç®€æ´ã€å‹å¥½çš„è‡ªç„¶è¯­è¨€ç›´æ¥å›ç­”ç”¨æˆ·ã€‚ä¸è¦æ SQLï¼Œä¸è¦ç”¨æŠ€æœ¯æœ¯è¯­ï¼Œä½¿ç”¨ä¸­æ–‡ã€‚"
        },
        {
            "role": "user",
            "content": f"åŸå§‹é—®é¢˜ï¼š{user_question}\n\næ‰§è¡Œçš„ SQLï¼š{sql}\n\næŸ¥è¯¢ç»“æœï¼š\n{result_text}"
        }
    ]

    response = client.chat.completions.create(
        model="qwen-plus",
        messages=messages,
        temperature=0.3
    )
    return response.choices[0].message.content.strip()
# -----------------------------
# æ–‡ä»¶æ•°æ®æºæ”¯æŒï¼ˆExcel/CSVï¼‰
# -----------------------------

def load_dataframe_from_file(uploaded_file):
    """å®‰å…¨åŠ è½½ç”¨æˆ·ä¸Šä¼ çš„ Excel/CSV æ–‡ä»¶ä¸º DataFrame"""
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        else:
            return None, "âŒ ä»…æ”¯æŒ .csv, .xlsx, .xls æ–‡ä»¶"
        return df, None
    except Exception as e:
        return None, f"âŒ æ–‡ä»¶è§£æå¤±è´¥: {str(e)}"

def get_file_schema(df: pd.DataFrame):
    """ä» DataFrame æå– schema ä¾› AI ä½¿ç”¨"""
    schema = {}
    # å‡è®¾æ•´ä¸ªæ–‡ä»¶æ˜¯ä¸€ä¸ªâ€œè¡¨â€ï¼Œå‘½åä¸º 'uploaded_data'
    schema["uploaded_data"] = [
        {"column": col, "type": str(df[col].dtype)}
        for col in df.columns
    ]
    return schema
def ask_ai_answer_from_file(user_question: str, schema_info: dict, sample_data: str):
    """è®© AI ç›´æ¥åŸºäº schema å’Œæ•°æ®æ ·æœ¬å›ç­”é—®é¢˜ï¼Œä¸ç”Ÿæˆ SQL"""
    client = get_ai_client()
    
    system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚ç”¨æˆ·ä¸Šä¼ äº†ä¸€ä¸ªæ•°æ®æ–‡ä»¶ï¼Œç»“æ„å¦‚ä¸‹ï¼š

è¡¨åï¼šuploaded_data
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

ä»¥ä¸‹æ˜¯å‰ 5 è¡Œæ•°æ®æ ·æœ¬ï¼ˆç”¨åˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰ï¼š
{sample_data}

è¯·æ ¹æ®ç”¨æˆ·çš„åŸå§‹é—®é¢˜ï¼Œç›´æ¥ç”¨ä¸­æ–‡ç»™å‡ºç®€æ´ã€å‡†ç¡®çš„è‡ªç„¶è¯­è¨€å›ç­”ã€‚
- ä¸è¦æâ€œSQLâ€ã€â€œæŸ¥è¯¢â€ã€â€œè¡¨â€ç­‰æŠ€æœ¯æœ¯è¯­
- å¦‚æœæ•°æ®ä¸è¶³ä»¥å›ç­”ï¼Œè¯·è¯´â€œæ•°æ®ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€æˆ–â€œéœ€è¦æ›´å¤šä¿¡æ¯â€
- å›ç­”è¦å‹å¥½ã€ä¸“ä¸šã€é¢å‘ä¸šåŠ¡å†³ç­–
"""

    response = client.chat.completions.create(
        model="qwen-plus",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_question}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()
# -----------------------------
# ä¸»åº”ç”¨
# -----------------------------
def run():
    st.title("ğŸ¤– AI é¢†å¯¼å†³ç­–åŠ©æ‰‹")
    st.caption("æ”¯æŒ PostgreSQL / MySQL / SQLite / Oracle / Excel / CSV")

    # é€‰æ‹©æ•°æ®æºç±»å‹ï¼šæ•°æ®åº“ or æ–‡ä»¶
    data_source = st.radio(
        "é€‰æ‹©æ•°æ®æºç±»å‹",
        ("æ•°æ®åº“", "Excel/CSV æ–‡ä»¶"),
        horizontal=True
    )

    if data_source == "æ•°æ®åº“":
        # ========== åŸæœ‰æ•°æ®åº“é€»è¾‘ï¼ˆå®Œå…¨ä¿ç•™ï¼‰ ==========
        db_type_name = st.selectbox("1ï¸âƒ£ é€‰æ‹©æ•°æ®åº“ç±»å‹", list(DB_TYPES.keys()))
        db_type = DB_TYPES[db_type_name]

        config = {}
        if db_type == "sqlite":
            uploaded_file = st.file_uploader("2ï¸âƒ£ ä¸Šä¼  SQLite æ–‡ä»¶ (.db, .sqlite)", type=["db", "sqlite"])
            if uploaded_file:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".db") as tmp:
                    tmp.write(uploaded_file.getvalue())
                    config["file_path"] = tmp.name
        else:
            config["host"] = st.text_input("ä¸»æœº (Host)", value="localhost")
            default_port = {"postgresql": 5432, "mysql": 3306, "oracle": 1521}
            config["port"] = st.number_input("ç«¯å£ (Port)", value=default_port[db_type], min_value=1, max_value=65535)
            if db_type != "oracle":
                config["database"] = st.text_input("æ•°æ®åº“å (Database)")
            else:
                config["service_name"] = st.text_input("æœåŠ¡å (Service Name)")
            config["user"] = st.text_input("ç”¨æˆ·å (User)")
            config["password"] = st.text_input("å¯†ç  (Password)", type="password")

        if st.button("ğŸ§ª æµ‹è¯•è¿æ¥"):
            if db_type == "sqlite" and "file_path" not in config:
                st.error("è¯·å…ˆä¸Šä¼  SQLite æ–‡ä»¶")
            elif db_type != "sqlite" and not all(
                config.get(k) for k in ["host", "port", "user", "password"] 
                if k in config
            ):
                st.error("è¯·å¡«å†™æ‰€æœ‰å¿…è¦å­—æ®µ")
            else:
                success, msg = test_database_connection(db_type, config)
                if success:
                    st.success(msg)
                    st.session_state.db_config = config
                    st.session_state.db_type = db_type
                    st.session_state.data_mode = "database"
                else:
                    st.error(msg)

        # AI åŠ©æ‰‹ï¼ˆæ•°æ®åº“æ¨¡å¼ï¼‰
        if "db_config" in st.session_state and st.session_state.get("data_mode") == "database":
            st.markdown("---")
            st.subheader("ğŸ’¬ é—®ä»»ä½•å…³äºä½ æ•°æ®çš„é—®é¢˜")

            schema = get_db_schema(st.session_state.db_type, st.session_state.db_config)
            if not schema:
                st.warning("æ— æ³•åŠ è½½æ•°æ®ç»“æ„")
                return

            if "ai_chat" not in st.session_state:
                st.session_state.ai_chat = []

            # æ˜¾ç¤ºå†å²
            for msg in st.session_state.ai_chat:
                with st.chat_message("user"):
                    st.markdown(msg["user"])
                with st.chat_message("assistant"):
                    st.markdown(msg["answer"])
                    if "sql" in msg:
                        with st.expander("ğŸ” æŠ€æœ¯è¯¦æƒ…"):
                            st.code(msg["sql"], language="sql")
                            st.dataframe(msg["df"], use_container_width=True)

            # ç”¨æˆ·è¾“å…¥
            if prompt := st.chat_input("ä¾‹å¦‚ï¼šæœ€è¿‘åˆ©æ¶¦æœ€é«˜çš„é”€å”®æ˜¯å“ªç¬”ï¼Ÿ"):
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    with st.spinner("ğŸ§  AI æ­£åœ¨åˆ†ææ•°æ®..."):
                        ai_sql_result = ask_ai_generate_sql(prompt, schema)
                        if "error" in ai_sql_result:
                            st.error(ai_sql_result["error"])
                            st.session_state.ai_chat.append({
                                "user": prompt,
                                "answer": ai_sql_result["error"],
                                "sql": None,
                                "df": None
                            })
                            st.stop()

                        sql = ai_sql_result["sql"]
                        df, exec_error = execute_safe_query(st.session_state.db_type, st.session_state.db_config, sql)
                        if exec_error:
                            st.error(exec_error)
                            st.session_state.ai_chat.append({
                                "user": prompt,
                                "answer": exec_error,
                                "sql": sql,
                                "df": None
                            })
                            st.stop()

                        natural_answer = generate_natural_answer(prompt, sql, df)

                    st.markdown(natural_answer)

                    with st.expander("ğŸ” æŠ€æœ¯è¯¦æƒ…"):
                        st.code(sql, language="sql")
                        st.dataframe(df, use_container_width=True)

                    st.session_state.ai_chat.append({
                        "user": prompt,
                        "answer": natural_answer,
                        "sql": sql,
                        "df": df
                    })

            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯"):
                st.session_state.ai_chat = []
                st.rerun()

    else:
        # ========== æ–°å¢ï¼šExcel/CSV æ–‡ä»¶æ¨¡å¼ ==========
        st.subheader("ğŸ“ ä¸Šä¼ ä½ çš„ Excel æˆ– CSV æ–‡ä»¶")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            help="æ”¯æŒ .csv, .xlsx, .xls æ ¼å¼"
        )

        if uploaded_file:
            df, error = load_dataframe_from_file(uploaded_file)
            if error:
                st.error(error)
            else:
                st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} è¡Œæ•°æ®")
                st.session_state.file_df = df
                st.session_state.data_mode = "file"

                with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆï¼ˆå‰ 5 è¡Œï¼‰"):
                    st.dataframe(df.head(), use_container_width=True)

        # AI åŠ©æ‰‹ï¼ˆæ–‡ä»¶æ¨¡å¼ï¼‰
        if "file_df" in st.session_state and st.session_state.get("data_mode") == "file":
            st.markdown("---")
            st.subheader("ğŸ’¬ é—®ä»»ä½•å…³äºä½ æ•°æ®çš„é—®é¢˜")

            df = st.session_state.file_df
            schema = get_file_schema(df)
            # åªå–å‰ 10 è¡Œä½œä¸ºæ ·æœ¬ï¼Œé¿å… token è¶…é™
            sample_data = df.head(10).to_csv(sep='\t', index=False)

            if "ai_chat_file" not in st.session_state:
                st.session_state.ai_chat_file = []

            # æ˜¾ç¤ºå†å²
            for msg in st.session_state.ai_chat_file:
                with st.chat_message("user"):
                    st.markdown(msg["user"])
                with st.chat_message("assistant"):
                    st.markdown(msg["answer"])
                    if "df_preview" in msg:
                        with st.expander("ğŸ” ç›¸å…³æ•°æ®"):
                            st.dataframe(msg["df_preview"], use_container_width=True)

            # ç”¨æˆ·è¾“å…¥
            if prompt := st.chat_input("ä¾‹å¦‚ï¼šé”€å”®é¢æœ€é«˜çš„äº§å“æ˜¯ä»€ä¹ˆï¼Ÿ"):
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    with st.spinner("ğŸ§  AI æ­£åœ¨åˆ†ææ•°æ®..."):
                        answer = ask_ai_answer_from_file(prompt, schema, sample_data)

                    st.markdown(answer)

                    # ä¿å­˜å¯¹è¯ï¼ˆå¯é™„å¸¦å®Œæ•´æ•°æ®æˆ–ç‰‡æ®µç”¨äºå±•ç¤ºï¼‰
                    st.session_state.ai_chat_file.append({
                        "user": prompt,
                        "answer": answer,
                        "df_preview": df.head(10)  # æˆ–æ ¹æ®é—®é¢˜åŠ¨æ€ç­›é€‰ï¼ŒMVP ç”¨ head
                    })

            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯ï¼ˆæ–‡ä»¶æ¨¡å¼ï¼‰"):
                st.session_state.ai_chat_file = []
                st.rerun()