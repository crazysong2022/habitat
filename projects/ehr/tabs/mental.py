import streamlit as st
import pandas as pd
import json
from datetime import datetime, timedelta
import psycopg2
import plotly.express as px
from urllib.parse import urlparse
import os
from dotenv import load_dotenv

load_dotenv()

# ========== æ•°æ®åº“è¿æ¥ ==========
def get_ehr_db_connection():
    DATABASE_EHR_URL = os.getenv("DATABASE_EHR_URL")
    if not DATABASE_EHR_URL:
        st.error("âŒ ç¯å¢ƒå˜é‡ DATABASE_EHR_URL æœªè®¾ç½®")
        return None
    try:
        url = urlparse(DATABASE_EHR_URL)
        conn = psycopg2.connect(
            host=url.hostname,
            port=url.port or 5432,
            database=url.path[1:],
            user=url.username,
            password=url.password,
        )
        return conn
    except Exception as e:
        st.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None

# ========== EPDS é‡è¡¨é¢˜ç›®ï¼ˆä¸­æ–‡ç‰ˆæ ‡å‡†ï¼‰==========
EPDS_QUESTIONS = [
    "1. æˆ‘èƒ½å¤Ÿå› ä¸ºå¼€å¿ƒçš„äº‹è€Œç¬‘",
    "2. æˆ‘å¯¹äº‹æƒ…çš„å…´è¶£å‡å°‘",
    "3. æˆ‘æ„Ÿåˆ°ç„¦è™‘æˆ–ç´§å¼ ",
    "4. æˆ‘éš¾ä»¥å…¥ç¡",
    "5. æˆ‘æ„Ÿåˆ°éš¾è¿‡æˆ–æ²®ä¸§",
    "6. æˆ‘æ„Ÿåˆ°è‡ªå·±æ˜¯è´Ÿæ‹…",
    "7. æˆ‘æ— æ³•é›†ä¸­æ³¨æ„åŠ›",
    "8. æˆ‘å¯¹è‡ªå·±çš„æœªæ¥æ„Ÿåˆ°ç»æœ›",
    "9. æˆ‘æƒ³åˆ°ä¼¤å®³è‡ªå·±",
    "10. æˆ‘å“­å¾—æ¯”å¹³æ—¶å¤š"
]

EPDS_SCORES = [0, 1, 2, 3]  # 0=ä»ä¸ï¼Œ1=å¶å°”ï¼Œ2=ç»å¸¸ï¼Œ3=æ€»æ˜¯

# ========== è·å–ç”¨æˆ·æœ€è¿‘EPDSè®°å½• ==========
@st.cache_data(ttl=300)
def fetch_epds_records(ehr_id: int, limit: int = 5):
    conn = get_ehr_db_connection()
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT contents, created_at
                FROM data 
                WHERE ehr_id = %s AND items = 'å¿ƒç†' 
                  AND contents ? 'epds_score'
                ORDER BY created_at DESC
                LIMIT %s
            """, (ehr_id, limit))
            rows = cur.fetchall()
            records = []
            for contents, created_at in rows:
                if isinstance(contents, str):
                    try:
                        contents = json.loads(contents)
                    except:
                        continue
                if isinstance(contents, dict) and 'epds_score' in contents:
                    record = {
                        "date": created_at.strftime("%Y-%m-%d"),
                        "score": contents.get("epds_score", 0),
                        "answers": contents.get("epds_answers", []),
                        "note": contents.get("note", "")
                    }
                    records.append(record)
            return records
    except Exception as e:
        st.warning(f"âš ï¸ è·å–EPDSè®°å½•å¤±è´¥: {e}")
        return []
    finally:
        if conn:
            conn.close()

# ========== è·å–åŒ¿åäº¤æµå¸– ==========
@st.cache_data(ttl=600)
def fetch_mental_posts(ehr_id: int, limit: int = 10):
    conn = get_ehr_db_connection()
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT contents, created_at, id
                FROM data 
                WHERE items = 'å¿ƒç†-æ ‘æ´' 
                  AND (contents->>'is_anonymous')::boolean = true
                  AND (contents->>'is_visible')::boolean = true
                ORDER BY created_at DESC
                LIMIT %s
            """, (limit,))
            rows = cur.fetchall()
            posts = []
            for contents, created_at, post_id in rows:
                if isinstance(contents, str):
                    try:
                        contents = json.loads(contents)
                    except:
                        continue
                if isinstance(contents, dict):
                    posts.append({
                        "id": post_id,
                        "content": contents.get("content", ""),
                        "emotion_tags": contents.get("emotion_tags", []),
                        "created_at": created_at,
                        "likes": contents.get("likes", 0),
                        "replies": contents.get("replies", 0),
                        "user_label": contents.get("user_label", "åŒ¿åå­•å¦ˆ")
                    })
            return posts
    except Exception as e:
        st.warning(f"âš ï¸ è·å–æ ‘æ´å¸–å­å¤±è´¥: {e}")
        return []
    finally:
        if conn:
            conn.close()

# ========== æäº¤EPDSæµ‹è¯„ ==========
def submit_epds_test(ehr_id: int, answers: list, note: str = ""):
    conn = get_ehr_db_connection()
    if not conn:
        return False
    try:
        score = sum(answers)
        contents = {
            "epds_score": score,
            "epds_answers": answers,
            "note": note,
            "submitted_at": datetime.now().isoformat()
        }
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO data (ehr_id, contents, items, created_at)
                VALUES (%s, %s, 'å¿ƒç†', NOW())
            """, (ehr_id, json.dumps(contents, ensure_ascii=False)))
        conn.commit()
        return True
    except Exception as e:
        st.error(f"âŒ ä¿å­˜æµ‹è¯„å¤±è´¥: {e}")
        if conn:
            conn.rollback()
        return False
    finally:
        if conn:
            conn.close()

# ========== æäº¤æ ‘æ´å¸–å­ ==========
def submit_anonymous_post(ehr_id: int, content: str, emotion_tags: list, user_label: str):
    conn = get_ehr_db_connection()
    if not conn:
        return False
    try:
        contents = {
            "content": content,
            "emotion_tags": emotion_tags,
            "user_label": user_label,
            "is_anonymous": True,
            "is_visible": True,
            "likes": 0,
            "replies": 0,
            "created_by": ehr_id,
            "created_at": datetime.now().isoformat()
        }
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO data (ehr_id, contents, items, created_at)
                VALUES (%s, %s, 'å¿ƒç†-æ ‘æ´', NOW())
            """, (ehr_id, json.dumps(contents, ensure_ascii=False)))
        conn.commit()
        return True
    except Exception as e:
        st.error(f"âŒ å‘å¸ƒå¤±è´¥: {e}")
        if conn:
            conn.rollback()
        return False
    finally:
        if conn:
            conn.close()

# ========== ç‚¹èµå¸–å­ ==========
def like_post(post_id: int):
    conn = get_ehr_db_connection()
    if not conn:
        return False
    try:
        with conn.cursor() as cur:
            cur.execute("""
                UPDATE data 
                SET contents = jsonb_set(contents, '{likes}', (contents->>'likes')::int + 1)::jsonb
                WHERE id = %s AND items = 'å¿ƒç†-æ ‘æ´'
            """, (post_id,))
        conn.commit()
        return True
    except Exception as e:
        st.warning(f"âš ï¸ ç‚¹èµå¤±è´¥: {e}")
        return False
    finally:
        if conn:
            conn.close()

# ========== AIæƒ…æ„Ÿåˆ†æä¸åé¦ˆï¼ˆä½¿ç”¨ä½ çš„OpenAIå®¢æˆ·ç«¯ï¼‰==========
@st.cache_resource
def get_ai_client():
    from openai import OpenAI
    return OpenAI(
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )

def generate_epds_ai_feedback(ehr_id: int, score: int, answers: list):
    """æ ¹æ®EPDSåˆ†æ•°ç”Ÿæˆä¸ªæ€§åŒ–ã€æ¸©æš–ã€éè¯Šæ–­æ€§AIåé¦ˆ"""
    client = get_ai_client()

    # æ„é€ ä¸Šä¸‹æ–‡æ‘˜è¦
    answer_descriptions = []
    for i, a in enumerate(answers):
        desc = f"{EPDS_QUESTIONS[i]}ï¼š{'å‡ ä¹ä¸' if a==0 else 'å¶å°”' if a==1 else 'ç»å¸¸' if a==2 else 'æ€»æ˜¯'}"
        answer_descriptions.append(desc)

    system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­•æœŸå¿ƒç†æ”¯æŒAIåŠ©æ‰‹ï¼Œç›®æ ‡æ˜¯æä¾›æ¸©æš–ã€éè¯„åˆ¤ã€é¼“åŠ±æ€§çš„åé¦ˆã€‚
å½“å‰ç”¨æˆ·EPDSæ€»åˆ†ä¸º{score}åˆ†ï¼ˆæ»¡åˆ†30ï¼‰ï¼Œä»£è¡¨è½»åº¦è‡³ä¸­åº¦æƒ…ç»ªå›°æ‰°ï¼ˆéæŠ‘éƒç—‡è¯Šæ–­ï¼‰ã€‚
è¯·é¿å…ä½¿ç”¨åŒ»å­¦æœ¯è¯­å¦‚â€œæŠ‘éƒâ€ã€â€œç„¦è™‘ç—‡â€ã€‚ä½¿ç”¨å…±æƒ…è¯­è¨€ï¼Œå¼ºè°ƒâ€œè¿™æ˜¯å¸¸è§çš„å­•æœŸä½“éªŒâ€ï¼Œå¹¶ç»™äºˆå¸Œæœ›å’Œèµ„æºã€‚
å›å¤å¿…é¡»ï¼š  
- ä½¿ç”¨ç¬¬ä¸€äººç§°â€œä½ â€  
- ä¸è¦ç»™å‡ºåŒ»ç–—å»ºè®®ï¼ˆå¦‚â€œå»çœ‹åŒ»ç”Ÿâ€ï¼‰ï¼Œæ”¹ä¸ºâ€œä½ å¯ä»¥è€ƒè™‘â€¦â€  
- åŒ…å«ä¸€å¥å…³äºå®å®çš„æ¸©æŸ”è¯è¯­  
- ä¿æŒç®€çŸ­ï¼ˆä¸è¶…è¿‡150å­—ï¼‰  
- ä½¿ç”¨ä¸­æ–‡ï¼Œè¯­æ°”å¦‚ä¸€ä½æ‡‚ä½ çš„å§å¦¹  

ç¤ºä¾‹è¾“å‡ºï¼š  
â€œä½ æœ€è¿‘å¸¸å¸¸æ„Ÿåˆ°ç–²æƒ«å’Œéš¾è¿‡ï¼Œè¿™çœŸçš„ä¸å®¹æ˜“ã€‚ä½†ä½ çŸ¥é“å—ï¼Ÿå¾ˆå¤šå­•å¦ˆå¦ˆåœ¨28å‘¨å·¦å³éƒ½ä¼šè¿™æ ·ï¼Œä¸æ˜¯å› ä¸ºä½ ä¸å¤Ÿå¥½ï¼Œè€Œæ˜¯èº«ä½“åœ¨æ‚„æ‚„æ”¹å˜ã€‚ä½ å·²ç»åšå¾—å¾ˆå¥½äº†â€”â€”å“ªæ€•åªæ˜¯åšæŒæ¯å¤©æ‘¸ä¸€æ‘¸å®å®çš„å°è„šï¼Œé‚£éƒ½æ˜¯çˆ±çš„è¯æ˜ã€‚ä½ ä¸æ˜¯ä¸€ä¸ªäººåœ¨èµ°è¿™æ®µè·¯ã€‚â€"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"ç”¨æˆ·å›ç­”ï¼š{'; '.join(answer_descriptions)}"}
    ]

    try:
        response = client.chat.completions.create(
            model="qwen-plus",
            messages=messages,
            temperature=0.7,
            max_tokens=200
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return "ä½ çš„æƒ…ç»ªå€¼å¾—è¢«æ¸©æŸ”å¯¹å¾…ã€‚å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥è¯•ç€å†™ä¸‹ä»Šå¤©è®©ä½ æ„Ÿåˆ°ä¸€ç‚¹ç‚¹æ¸©æš–çš„å°äº‹ï¼Œæˆ‘ä¼šä¸€ç›´åœ¨è¿™é‡Œé™ªç€ä½ ã€‚"

# ========== ä¸»å‡½æ•° ==========
def render_tabs(ehr_id: int):
    st.markdown("### ğŸ§˜â€â™€ï¸ å­•æœŸå¿ƒç†æ”¯æŒç³»ç»Ÿ â€”â€” ä½ çš„æƒ…ç»ªï¼Œæˆ‘æ¥æ¥ä½")

    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“‹ EPDSæµ‹è¯„ä¸AIåé¦ˆ",
        "ğŸ’¬ åŒ¿åæ ‘æ´ Â· è¯´è¯´å¿ƒé‡Œè¯",
        "ğŸŒ± æƒ…ç»ªæ—¥è®° Â· è®°å½•å¾®å…‰",
        "ğŸ‘¥ åŒè¡Œè€…åœ°å›¾ Â· ä½ ä¸æ˜¯ä¸€ä¸ªäºº"
    ])

    # ==================== TAB 1: EPDSæµ‹è¯„ä¸AIåé¦ˆ ====================
    with tab1:
        st.subheader("ğŸ“‹ ä½ çš„å­•æœŸæƒ…ç»ªè‡ªæµ‹ï¼ˆEPDSé‡è¡¨ï¼‰")

        st.info("""
        EPDSï¼ˆçˆ±ä¸å ¡äº§åæŠ‘éƒé‡è¡¨ï¼‰æ˜¯å›½é™…é€šç”¨çš„ç­›æŸ¥å·¥å…·ï¼Œå¸®åŠ©ä½ äº†è§£è‡ªå·±çš„æƒ…ç»ªçŠ¶æ€ã€‚  
        è¿™ä¸æ˜¯è¯Šæ–­ï¼Œè€Œæ˜¯ä¸€é¢é•œå­â€”â€”å¸®ä½ çœ‹åˆ°ï¼š**ä½ æ­£åœ¨ç»å†ä»€ä¹ˆï¼Œä»¥åŠä½ å¹¶ä¸å­¤å•ã€‚**
        """)

        # æ˜¾ç¤ºå†å²è®°å½•
        recent_records = fetch_epds_records(ehr_id, 3)
        if recent_records:
            st.markdown("#### ğŸ“Š ä½ æœ€è¿‘çš„æµ‹è¯„è®°å½•")
            df_hist = pd.DataFrame(recent_records)
            df_hist['score'] = df_hist['score'].astype(int)
            fig = px.line(
                df_hist,
                x="date",
                y="score",
                markers=True,
                title="ğŸ“ˆ ä½ çš„æƒ…ç»ªæ³¢åŠ¨è¶‹åŠ¿ï¼ˆEPDSè¯„åˆ†ï¼‰",
                labels={"score": "EPDSå¾—åˆ†", "date": "æ—¥æœŸ"},
                color_discrete_sequence=["#FF6B6B"]
            )
            fig.update_layout(
                yaxis_range=[0, 30],
                shapes=[
                    dict(type="line", x0=0, x1=1, y0=10, y1=10, line=dict(color="orange", width=2, dash="dash"), xref="paper"),
                    dict(type="line", x0=0, x1=1, y0=13, y1=13, line=dict(color="red", width=2, dash="dash"), xref="paper")
                ],
                annotations=[
                    dict(x=0.5, y=10.5, text="â‰¥10ï¼šå…³æ³¨ä¿¡å·", showarrow=False, font=dict(size=10)),
                    dict(x=0.5, y=13.5, text="â‰¥13ï¼šå»ºè®®å’¨è¯¢", showarrow=False, font=dict(size=10))
                ]
            )
            st.plotly_chart(fig, use_container_width=True)

        # å¼€å§‹æµ‹è¯„
        st.divider()
        st.markdown("### âœï¸ è¯·æ ¹æ®æœ€è¿‘ä¸€å‘¨çš„æ„Ÿå—ä½œç­”ï¼ˆæ¯é¢˜é€‰ä¸€é¡¹ï¼‰")

        answers = []
        for i, q in enumerate(EPDS_QUESTIONS):
            st.markdown(f"**{q}**")
            ans = st.radio(
                f"é—®é¢˜ {i+1}",
                options=["ä»ä¸", "å¶å°”", "ç»å¸¸", "æ€»æ˜¯"],
                index=0,
                key=f"epds_{i}",
                horizontal=True
            )
            answers.append(EPDS_SCORES[["ä»ä¸", "å¶å°”", "ç»å¸¸", "æ€»æ˜¯"].index(ans)])

        total_score = sum(answers)

        # æäº¤æŒ‰é’®
        if st.button("âœ… æäº¤æµ‹è¯„ç»“æœ", type="primary"):
            note = st.text_input("æƒ³è¡¥å……ä»€ä¹ˆï¼Ÿï¼ˆå¯é€‰ï¼‰", key="epds_note")
            if submit_epds_test(ehr_id, answers, note):
                st.success("ğŸ‰ æµ‹è¯„å·²æäº¤ï¼AIæ­£åœ¨ä¸ºä½ ç”Ÿæˆä¸“å±åé¦ˆâ€¦")
                
                # ç”ŸæˆAIåé¦ˆ
                with st.spinner("ğŸ§  AIæ­£åœ¨ç”¨å¿ƒå€¾å¬ä½ â€¦"):
                    feedback = generate_epds_ai_feedback(ehr_id, total_score, answers)
                
                st.markdown("### â¤ï¸ ä½ çš„ä¸“å±å¿ƒç†åé¦ˆ")
                st.info(feedback)
                
                # æ ¹æ®åˆ†æ•°ç»™å‡ºæ¸©å’Œå»ºè®®
                if total_score >= 13:
                    st.warning("""
                    > ğŸŒŸ ä½ çš„å¾—åˆ†æç¤ºä½ å¯èƒ½æ­£åœ¨ç»å†è¾ƒæ˜æ˜¾çš„æƒ…ç»ªæ³¢åŠ¨ã€‚  
                    > è¿™ä¸ä»£è¡¨ä½ â€œä¸å¥½â€æˆ–â€œå¤±è´¥â€ï¼Œè€Œæ˜¯ä½ çš„èº«ä½“åœ¨æé†’ä½ ï¼šä½ éœ€è¦æ›´å¤šæ”¯æŒã€‚  
                    > ä½ ä¸æ˜¯ä¸€ä¸ªäººã€‚å¾ˆå¤šå­•å¦ˆå¦ˆéƒ½æ›¾èµ°è¿‡è¿™æ¡è·¯ã€‚  
                    > å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥å’Œå®¶äººèŠèŠï¼Œæˆ–è€…é¢„çº¦ä¸€æ¬¡äº§ç§‘å¿ƒç†å’¨è¯¢ã€‚
                    """)
                elif total_score >= 10:
                    st.info("""
                    > ğŸŒ± ä½ ç°åœ¨çš„æ„Ÿå—å¾ˆçœŸå®ï¼Œä¹Ÿå¾ˆå¸¸è§ã€‚  
                    > å¾ˆå¤šå­•å¦ˆå¦ˆåœ¨å­•ä¸­æœŸä¼šæ„Ÿåˆ°ç–²æƒ«ã€æ•æ„Ÿã€ç”šè‡³è«åæµæ³ªâ€”â€”è¿™ä¸æ˜¯è½¯å¼±ï¼Œæ˜¯ç”Ÿå‘½æ­£åœ¨é‡å¡‘ä½ çš„å†…å¿ƒã€‚  
                    > ä½ å·²ç»å¾ˆå‹‡æ•¢äº†ï¼Œè®°å¾—å¯¹è‡ªå·±æ¸©æŸ”ä¸€ç‚¹ã€‚
                    """)
                else:
                    st.success("""
                    > ğŸŒ ä½ çš„æƒ…ç»ªçŠ¶æ€ç¨³å®šï¼Œè°¢è°¢ä½ ç…§é¡¾å¥½è‡ªå·±ã€‚  
                    > å³ä½¿æ²¡æœ‰å¤§èµ·å¤§è½ï¼Œä½ çš„æ„Ÿå—ä¾ç„¶é‡è¦ã€‚  
                    > ç»§ç»­ä¿æŒè¿™ä»½è§‰å¯Ÿå§â€”â€”ä½ å·²ç»åœ¨åšä¸€ä»¶éå¸¸äº†ä¸èµ·çš„äº‹ï¼š**è®¤çœŸåœ°æ´»ç€ã€‚**
                    """)
        
        st.caption("ğŸ’¡ EPDSå¾—åˆ†è¯´æ˜ï¼š0â€“9 åˆ†ï¼šæ­£å¸¸ï¼›10â€“12 åˆ†ï¼šè½»åº¦å›°æ‰°ï¼›13â€“30 åˆ†ï¼šéœ€å…³æ³¨")

    # ==================== TAB 2: åŒ¿åæ ‘æ´ ====================
    with tab2:
        st.subheader("ğŸ’¬ åŒ¿åæ ‘æ´ Â· è¯´ç»™æ‡‚çš„äººå¬")

        st.info("""
        åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥**å®Œå…¨åŒ¿å**åœ°è¯´å‡ºä»»ä½•è¯ï¼š  
        â€œæˆ‘è®¨åŒæ€€å­•â€ã€â€œæˆ‘æ€•å½“å¦ˆå¦ˆâ€ã€â€œæˆ‘ä»Šå¤©å“­äº†å¾ˆä¹…â€ã€â€œæ²¡äººæ‡‚æˆ‘çš„ç´¯â€â€¦â€¦  
        ä½ ä¼šè¢«å¬è§ï¼Œä¸ä¼šè¢«è¯„åˆ¤ã€‚
        """)

        # æƒ…ç»ªæ ‡ç­¾é€‰æ‹©å™¨
        emotion_tags = [
            "ç–²æƒ«", "å­¤ç‹¬", "å®³æ€•", "å†…ç–š", "æ„¤æ€’", "æœŸå¾…", "æ„ŸåŠ¨", "å¹³é™", "æ— è¯­", "æƒ³å“­"
        ]
        selected_tags = st.multiselect("âœ¨ ä½ æƒ³ç”¨å“ªäº›è¯å½¢å®¹æ­¤åˆ»çš„å¿ƒæƒ…ï¼Ÿï¼ˆå¯å¤šé€‰ï¼‰", emotion_tags, max_selections=5)

        # æ–‡æœ¬è¾“å…¥
        post_content = st.text_area(
            "ğŸ“ æŠŠå¿ƒé‡Œè¯è¯´å‡ºæ¥å§ï¼ˆé™500å­—ï¼‰",
            placeholder="æ¯”å¦‚ï¼šä»Šå¤©è€å…¬è¯´â€˜ä½ èƒ–äº†â€™ï¼Œæˆ‘èº²åœ¨å•æ‰€å“­äº†å¥½ä¹…â€¦ä½†å®å®è¸¢äº†æˆ‘ä¸€ä¸‹ï¼Œæˆ‘åˆç¬‘äº†ã€‚",
            height=150
        )

        # ç”¨æˆ·æ ‡ç­¾ï¼ˆå¢å¼ºå½’å±æ„Ÿï¼‰
        user_label_options = [
            "å­•æ—©æœŸï¼ˆ<12å‘¨ï¼‰", "å­•ä¸­æœŸï¼ˆ13â€“28å‘¨ï¼‰", "å­•æ™šæœŸï¼ˆ29å‘¨+ï¼‰",
            "é«˜é¾„å­•å¦ˆ", "äºŒèƒå¦ˆå¦ˆ", "ç¬¬ä¸€æ¬¡å½“å¦ˆå¦ˆ", "å¤‡å­•å¾ˆä¹…æ‰æ€€ä¸Š", "å•äº²å¦ˆå¦ˆ"
        ]
        user_label = st.selectbox("ğŸ‘©â€âš•ï¸ ä½ æ˜¯å“ªç§å­•å¦ˆï¼Ÿï¼ˆä»…ç”¨äºåˆ†ç±»ï¼Œä¸æ˜¾ç¤ºèº«ä»½ï¼‰", user_label_options)

        if st.button("ğŸŒ¿ å‘å¸ƒåˆ°æ ‘æ´", type="primary"):
            if not post_content.strip():
                st.error("âš ï¸ è¯·å…ˆå†™ä¸‹ä½ æƒ³è¯´çš„è¯å“¦ï½")
            else:
                if submit_anonymous_post(ehr_id, post_content, selected_tags, user_label):
                    st.success("ğŸ’Œ ä½ çš„å£°éŸ³å·²è¢«é€è¾¾ï¼Œæœ‰äººæ­£åœ¨è¯»å®ƒã€‚")
                    st.balloons()
                    st.rerun()

        st.divider()

        # å±•ç¤ºæœ€æ–°å¸–å­
        st.markdown("### ğŸŒ¿ æœ€è¿‘çš„å¿ƒå£°")
        posts = fetch_mental_posts(ehr_id, 10)
        if not posts:
            st.info("ğŸŒ³ è¿˜æ²¡æœ‰äººåˆ†äº«è¿‡å¿ƒäº‹ï¼Œä½ æ„¿æ„æˆä¸ºç¬¬ä¸€ä¸ªå—ï¼Ÿ")
        else:
            for post in posts:
                with st.expander(f"ğŸ’¬ {post['user_label']} Â· {post['created_at'].strftime('%m/%d %H:%M')}"):
                    st.write(post["content"])
                    if post["emotion_tags"]:
                        tags_str = " ".join([f"`#{tag}`" for tag in post["emotion_tags"]])
                        st.markdown(f"*{tags_str}*")

                    col1, col2 = st.columns([1, 4])
                    with col1:
                        if st.button("â¤ï¸ ç‚¹èµ", key=f"like_{post['id']}"):
                            if like_post(post["id"]):
                                st.rerun()
                    with col2:
                        st.caption(f"{post['likes']} ä¸ªèµ Â· {post['replies']} æ¡å›åº”")

                    # æ¨¡æ‹Ÿå›å¤åŠŸèƒ½ï¼ˆå¯æ‰©å±•ï¼‰
                    reply = st.text_input("ğŸ’¬ å›åº”ä¸€å¥æ¸©æš–çš„è¯ï¼ˆä»…ä½ å¯è§ï¼‰", key=f"reply_{post['id']}")
                    if reply and st.button("ğŸ’Œ å‘é€ç§è¯­", key=f"send_reply_{post['id']}"):
                        st.success("ğŸ’Œ ä½ çš„å¿ƒæ„ï¼Œå·²æ‚„æ‚„é€è¾¾ã€‚")

    # ==================== TAB 3: æƒ…ç»ªæ—¥è®° Â· è®°å½•å¾®å…‰ ====================
    with tab3:
        st.subheader("ğŸŒ± æƒ…ç»ªæ—¥è®° Â· è®°å½•å±äºä½ çš„å¾®å…‰æ—¶åˆ»")

        st.info("""
        æ¯å¤©åªéœ€ä¸‰åˆ†é’Ÿï¼Œå†™ä¸‹ä¸€ä»¶è®©ä½ æ„Ÿè§‰â€œè¿˜å¥½â€çš„å°äº‹ã€‚  
        ä¸å¿…ä¼Ÿå¤§ï¼Œä¸å¿…å®Œç¾â€”â€”  
        åªè¦æ˜¯**ä½ çœŸå®æ„Ÿå—åˆ°çš„æ¸©æš–**ï¼Œå°±å€¼å¾—è¢«è®°å½•ã€‚
        """)

        prompt = st.selectbox(
            "ä»Šå¤©ï¼Œæ˜¯ä»€ä¹ˆå°äº‹è®©ä½ è§‰å¾—â€˜è¿˜å¥½â€™ï¼Ÿ",
            [
                "å®å®åŠ¨äº†ä¸€ä¸‹",
                "é˜³å…‰ç…§è¿›çª—æˆ·",
                "è€å…¬ç»™æˆ‘å€’äº†æ¯æ¸©æ°´",
                "å¬åˆ°ä¸€é¦–æ­Œï¼Œæƒ³èµ·äº†å¦ˆå¦ˆ",
                "æœ‹å‹å‘æ¥ä¸€å¥â€˜ä½ çœŸæ£’â€™",
                "åƒäº†ä¸€é¢—å–œæ¬¢çš„æ°´æœ",
                "ç¡äº†ä¸€ä¸ªè¸å®çš„åˆè§‰",
                "æˆ‘åŸè°…äº†ä»Šå¤©çš„è‡ªå·±"
            ],
            key="journal_prompt"
        )

        daily_entry = st.text_area(
            "âœï¸ è¯·å†™ä¸‹ä½ çš„å¾®å…‰æ—¶åˆ»ï¼ˆå¯è‡ªç”±å‘æŒ¥ï¼‰",
            placeholder="ä¾‹å¦‚ï¼šä»Šå¤©æ—©ä¸Šï¼Œå®å®åœ¨è‚šå­é‡Œç¿»äº†ä¸ªè·Ÿå¤´ï¼Œåƒåœ¨è·³èŠ­è•¾ã€‚é‚£ä¸€åˆ»ï¼Œæˆ‘è§‰å¾—æ‰€æœ‰è¾›è‹¦éƒ½å€¼å¾—äº†ã€‚",
            height=100
        )

        if st.button("ğŸ“– ä¿å­˜ä»Šæ—¥æ—¥è®°"):
            if daily_entry.strip():
                contents = {
                    "type": "emotional_journal",
                    "entry": daily_entry,
                    "prompt": prompt,
                    "created_at": datetime.now().isoformat()
                }
                if save_emotion_journal(ehr_id, contents):
                    st.success("âœ¨ å·²ä¿å­˜ã€‚ä½ æ­£åœ¨ä¸ºè‡ªå·±ç§ä¸‹ä¸€ç‰‡æ¸©æŸ”çš„æ£®æ—ã€‚")
                    st.rerun()
            else:
                st.warning("ğŸ“ è¯·å…ˆå†™ä¸‹ä½ çš„æ„Ÿå—å“¦ï½")

        # å±•ç¤ºæœ€è¿‘æ—¥è®°
        st.markdown("### ğŸ“– ä½ çš„å¾®å…‰æ”¶è—å¤¹")
        journal_entries = fetch_emotion_journals(ehr_id, 5)
        if journal_entries:
            for entry in journal_entries:
                with st.expander(f"ğŸ“… {entry['date']} Â· {entry['prompt']}"):
                    st.write(entry["entry"])
                    st.caption(f"ğŸ’­ å½“æ—¶ä½ é€‰æ‹©çš„å…³é”®è¯ï¼š{entry['prompt']}")
        else:
            st.info("ğŸ•Šï¸ ä½ è¿˜æ²¡æœ‰è®°å½•è¿‡å¾®å…‰æ—¶åˆ»ã€‚ä»Šå¤©ï¼Œæ„¿æ„å†™ä¸‹ä¸€ä¸ªå—ï¼Ÿ")

    # ==================== TAB 4: åŒè¡Œè€…åœ°å›¾ ====================
    with tab4:
        st.subheader("ğŸ‘¥ åŒè¡Œè€…åœ°å›¾ Â· ä½ ä¸æ˜¯ä¸€ä¸ªäºº")

        st.info("""
        è¿™é‡Œä¸æ˜¯â€œå¥½å‹åˆ—è¡¨â€ï¼Œè€Œæ˜¯ä¸€ä¸ª**éšå½¢çš„å­•å¦ˆå¦ˆç¤¾ç¾¤**ã€‚  
        æˆ‘ä»¬çŸ¥é“ï¼š**å½“ä½ çŸ¥é“â€œæœ‰äººå’Œä½ ä¸€æ ·â€ï¼Œä½ å°±ä¸å†å­¤å•ã€‚**  
        æ‰€æœ‰ä¿¡æ¯å‡åŒ¿åå¤„ç†ï¼Œéšç§ç”±ç³»ç»Ÿä¿éšœã€‚
        """)

        # ç»Ÿè®¡æ•°æ®
        conn = get_ehr_db_connection()
        if conn:
            try:
                with conn.cursor() as cur:
                    cur.execute("SELECT COUNT(*) FROM data WHERE items = 'å¿ƒç†' AND contents ? 'epds_score'")
                    total_assessments = cur.fetchone()[0]
                    cur.execute("SELECT COUNT(*) FROM data WHERE items = 'å¿ƒç†-æ ‘æ´' AND is_anonymous = true")
                    total_posts = cur.fetchone()[0]
            except:
                total_assessments = 0
                total_posts = 0
            finally:
                conn.close()

        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“Š æ€»å…±å®Œæˆæµ‹è¯„", f"{total_assessments} äººæ¬¡")
        with col2:
            st.metric("ğŸ’¬ æ€»å…±å€¾è¯‰å¿ƒå£°", f"{total_posts} æ¡")

        # åœ°å›¾å¯è§†åŒ–ï¼ˆæ¨¡æ‹Ÿï¼‰
        st.markdown("### ğŸ—ºï¸ ä½ æ‰€åœ¨çš„ä½ç½®ï¼ˆè™šæ‹Ÿåœ°å›¾ï¼‰")

        # æ¨¡æ‹Ÿâ€œé™„è¿‘å­•å¦ˆâ€åˆ†å¸ƒ
        nearby_moms = [
            {"label": "å­•28å‘¨Â·äºŒèƒÂ·é«˜é¾„", "distance": "2.3km", "mood": "ç–²æƒ«ä½†æœŸå¾…"},
            {"label": "å­•16å‘¨Â·åˆä¸ºäººæ¯", "distance": "1.1km", "mood": "æœ‰ç‚¹æ…Œå¼ "},
            {"label": "å­•32å‘¨Â·å•äº²å¦ˆå¦ˆ", "distance": "5.8km", "mood": "åšå¼ºåˆæŸ”è½¯"},
            {"label": "å­•20å‘¨Â·å¤‡å­•ä¸‰å¹´ç»ˆäºæˆåŠŸ", "distance": "3.2km", "mood": "ä¸æ•¢ç›¸ä¿¡è¿™æ˜¯çœŸçš„"},
        ]

        for mom in nearby_moms:
            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"ğŸ”¹ **{mom['label']}** Â· {mom['mood']}")
                with col2:
                    st.caption(f"ğŸ“ è·ç¦»ï¼š{mom['distance']}")

        st.divider()

        # åŠ å…¥â€œåŒè¡Œè€…è®¡åˆ’â€
        st.markdown("### ğŸ¤ åŠ å…¥â€˜åŒè¡Œè€…è®¡åˆ’â€™")
        st.markdown("""
        å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘ä»¬å¯ä»¥ï¼š
        - åœ¨ä½ å®ŒæˆEPDSåï¼Œ**éšæœºåŒ¹é…ä¸€ä½åŒå­•å‘¨çš„å¦ˆå¦ˆ**ï¼Œå½¼æ­¤å‘é€ä¸€æ¡åŒ¿åé¼“åŠ±ä¿¡  
        - æ¯æœˆæ¨é€ä¸€æ¬¡ã€Šå­•å¦ˆæƒ…ç»ªè§‚å¯ŸæŠ¥å‘Šã€‹ï¼ˆä¸å«ä¸ªäººä¿¡æ¯ï¼‰  
        - ä½ å¯ä»¥åœ¨ã€æˆ‘çš„æ¡£æ¡ˆã€‘ä¸­å¼€å¯ã€Œå…è®¸è¢«åŒ¹é…ã€å¼€å…³
        """)

        if st.button("ğŸŒŸ æˆ‘æ„¿æ„åŠ å…¥åŒè¡Œè€…è®¡åˆ’"):
            st.success("ğŸ’« ä½ å·²åŠ å…¥ã€‚ç³»ç»Ÿå°†åœ¨ä½ ä¸‹æ¬¡æµ‹è¯„åï¼Œä¸ºä½ åŒ¹é…ä¸€ä½é»˜é»˜é™ªä¼´çš„ä¼™ä¼´ã€‚")
            st.balloons()

        st.caption("ğŸ”’ æ‰€æœ‰åŒ¹é…å‡ä¸ºç³»ç»Ÿè‡ªåŠ¨åŒ¿åå¤„ç†ï¼Œä½ æ°¸è¿œä¸ä¼šçŸ¥é“å¯¹æ–¹æ˜¯è°ï¼Œä½†ä½ çŸ¥é“ï¼šå¥¹æ‡‚ä½ ã€‚")

# ========== è¾…åŠ©å‡½æ•°ï¼šä¿å­˜æƒ…ç»ªæ—¥è®° ==========
def save_emotion_journal(ehr_id: int, contents: dict) -> bool:
    conn = get_ehr_db_connection()
    if not conn:
        return False
    try:
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO data (ehr_id, contents, items, created_at)
                VALUES (%s, %s, 'å¿ƒç†-æ—¥è®°', NOW())
            """, (ehr_id, json.dumps(contents, ensure_ascii=False)))
        conn.commit()
        return True
    except Exception as e:
        st.warning(f"âš ï¸ ä¿å­˜æ—¥è®°å¤±è´¥: {e}")
        return False
    finally:
        if conn:
            conn.close()

# ========== è·å–æƒ…ç»ªæ—¥è®° ==========
@st.cache_data(ttl=300)
def fetch_emotion_journals(ehr_id: int, limit: int = 5):
    conn = get_ehr_db_connection()
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT contents, created_at
                FROM data 
                WHERE ehr_id = %s AND items = 'å¿ƒç†-æ—¥è®°'
                ORDER BY created_at DESC
                LIMIT %s
            """, (ehr_id, limit))
            rows = cur.fetchall()
            journals = []
            for contents, created_at in rows:
                if isinstance(contents, str):
                    try:
                        contents = json.loads(contents)
                    except:
                        continue
                if isinstance(contents, dict):
                    journals.append({
                        "date": created_at.strftime("%m/%d"),
                        "entry": contents.get("entry", ""),
                        "prompt": contents.get("prompt", ""),
                        "created_at": created_at
                    })
            return journals
    except Exception as e:
        st.warning(f"âš ï¸ è·å–æ—¥è®°å¤±è´¥: {e}")
        return []
    finally:
        if conn:
            conn.close()