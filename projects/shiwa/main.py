import streamlit as st
import os, psycopg2, pandas as pd, plotly.express as px, plotly.graph_objects as go
from datetime import datetime, timedelta, time
from dotenv import load_dotenv
import uuid
from sqlalchemy import create_engine
import json
# ----------------------------- ç¯å¢ƒ & å¼•æ“ ----------------------------- #
load_dotenv()
DATABASE_URL = os.getenv("DATABASE_SHIWA_URL")
if not DATABASE_URL:
    st.error("âŒ æœªè®¾ç½®æ•°æ®åº“è¿æ¥URL"); st.stop()
SQLALCHEMY_URL = DATABASE_URL.replace("postgres://", "postgresql://") if DATABASE_URL.startswith("postgres://") else DATABASE_URL
engine = create_engine(SQLALCHEMY_URL)
# ----------------------------- è¿æ¥ä¸Šä¸‹æ–‡ ----------------------------- #
class DatabaseConnection:
    def __enter__(self):
        try:
            self.conn = psycopg2.connect(DATABASE_URL); return self.conn
        except Exception as e:
            st.error(f"ğŸ”— æ•°æ®åº“è¿æ¥å¤±è´¥: {e}"); return None
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.conn: self.conn.close()
# ----------------------------- ç¼“å­˜æŸ¥è¯¢ï¼ˆä¿æŒä¸å˜ï¼‰----------------------------- #
@st.cache_data(show_spinner=False)
def fetch_frog_types():
    with DatabaseConnection() as conn:
        if not conn: return []
        with conn.cursor() as cur:
            cur.execute("SELECT type_code, description FROM t_frog_type_dict WHERE is_active = true ORDER BY type_code")
            return cur.fetchall()
@st.cache_data(show_spinner=False)
def fetch_material_types():
    with DatabaseConnection() as conn:
        if not conn: return []
        with conn.cursor() as cur:
            cur.execute("SELECT type_code, name, unit FROM t_material_type_dict WHERE is_active = true ORDER BY name")
            return cur.fetchall()
@st.cache_data(show_spinner=False)
def fetch_incubation_pools(status=None):
    with DatabaseConnection() as conn:
        if not conn: return []
        with conn.cursor() as cur:
            if status:
                cur.execute("SELECT pool_no, location_info, current_status, current_batch_no FROM t_incubation_pool WHERE current_status = %s ORDER BY pool_no", (status,))
            else:
                cur.execute("SELECT pool_no, location_info, current_status, current_batch_no FROM t_incubation_pool ORDER BY pool_no")
            return cur.fetchall()
@st.cache_data(show_spinner=False)
def fetch_active_batches():
    with DatabaseConnection() as conn:
        if not conn: return []
        with conn.cursor() as cur:
            cur.execute("""SELECT batch_no, pool_no, input_type, input_time, initial_input, input_unit
                           FROM t_incubation_batch WHERE batch_status = 'ä½¿ç”¨ä¸­' ORDER BY input_time DESC""")
            return cur.fetchall()
# ----------------------------- åˆ†ææ•°æ®ç¼“å­˜æŸ¥è¯¢ï¼ˆä¿æŒä¸å˜ï¼‰----------------------------- #
@st.cache_data(show_spinner=False)
def get_batch_conversion_data(start_date=None, end_date=None):
    try:
        sql = """
            SELECT batch_no, pool_no, input_type, initial_input, input_unit,
                   input_time::date AS input_date, total_sorted_frog, conversion_rate, batch_status
            FROM   v_batch_conversion
            WHERE  1=1
        """
        params = []
        if start_date:
            sql += " AND input_time >= %s"
            params.append(start_date)
        if end_date:
            sql += " AND input_time <= %s"
            params.append(end_date)
        sql += " ORDER BY input_time DESC"
        return pd.read_sql(sql, engine, params=tuple(params))
    except Exception as e:
        st.error(f"è·å–æ‰¹æ¬¡è½¬åŒ–ç‡æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()
@st.cache_data(show_spinner=False)
def get_material_consumption_data(start_date=None, end_date=None):
    try:
        sql = """
            SELECT b.related_entity_id material_type, m.name material_name, m.unit material_unit,
                   SUM(b.operation_value) total_consumption,
                   DATE_TRUNC('day', b.operation_time) operation_date
            FROM   t_business_behavior_record b
            JOIN   t_material_type_dict m ON b.related_entity_id = m.type_code
            WHERE  b.behavior_type = 'å–‚é£Ÿ'
        """
        params = []
        if start_date:
            sql += " AND b.operation_time >= %s"
            params.append(start_date)
        if end_date:
            sql += " AND b.operation_time <= %s"
            params.append(end_date)
        sql += " GROUP BY material_type, material_name, material_unit, operation_date ORDER BY operation_date"
        return pd.read_sql(sql, engine, params=tuple(params))
    except Exception as e:
        st.error(f"è·å–ç‰©èµ„æ¶ˆè€—æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()
@st.cache_data(show_spinner=False)
def get_frog_inventory_data():
    try:
        sql = """SELECT i.frog_type_code, t.description frog_type, i.quantity, i.pool_area, i.last_update_time
                 FROM t_frog_inventory i
                 JOIN t_frog_type_dict t ON i.frog_type_code = t.type_code
                 ORDER BY t.parent_type, t.description, i.pool_area"""
        return pd.read_sql(sql, engine)
    except Exception as e:
        st.error(f"è·å–æˆè›™åº“å­˜æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()
@st.cache_data(show_spinner=False)
def get_sales_data(start_date=None, end_date=None):
    try:
        sql = """
            SELECT b.related_entity_id frog_type_code, t.description frog_type,
                   SUM(b.operation_value) total_sold,
                   DATE_TRUNC('day', b.operation_time) sale_date,
                   b.remarks
            FROM   t_business_behavior_record b
            JOIN   t_frog_type_dict t ON b.related_entity_id = t.type_code
            WHERE  b.behavior_type = 'é”€å”®æˆè›™'
        """
        params = []
        if start_date:
            sql += " AND b.operation_time >= %s"
            params.append(start_date)
        if end_date:
            sql += " AND b.operation_time <= %s"
            params.append(end_date)
        sql += " GROUP BY frog_type_code, frog_type, sale_date, b.remarks ORDER BY sale_date"
        return pd.read_sql(sql, engine, params=tuple(params))
    except Exception as e:
        st.error(f"è·å–é”€å”®æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()
@st.cache_data(ttl=10, show_spinner=False)
def get_pool_frog_inventory(pool_area: str):
    """
    æŸ¥è¯¢æŒ‡å®šæ± åŒºä¸­å„è›™ç±»å‹çš„åº“å­˜æ•°é‡
    è¿”å›: List[Tuple[type_code, description, quantity]]
    """
    with DatabaseConnection() as conn:
        if not conn:
            return []
        with conn.cursor() as cur:
            cur.execute("""
                SELECT i.frog_type_code, t.description, i.quantity
                FROM t_frog_inventory i
                JOIN t_frog_type_dict t ON i.frog_type_code = t.type_code
                WHERE i.pool_area = %s AND i.quantity > 0
                ORDER BY t.description
            """, (pool_area,))
            return cur.fetchall()
@st.cache_data(show_spinner=False)
def get_sorted_frog_total_by_source(source_cn: str):
    """
    source_cn: 'è‡ªå…»åµ' / 'å¤–è´­èŒèšª' / 'å¤–è´­å¹¼è›™' / 'å¤–è´­æˆè›™'
    æ ¹æ® batch_no å‰ç¼€ç»Ÿè®¡å·²åˆ†æ‹£æ€»é‡
    """
    prefix_map = {
        "è‡ªå…»åµ": "è‡ªå…»åµ-%",
        "å¤–è´­èŒèšª": "å¤–è´­èŒèšª-%",
        "å¤–è´­å¹¼è›™": "å¤–è´­å¹¼è›™-%",
        "å¤–è´­æˆè›™": "å¤–è´­æˆè›™-%",
    }
    pattern = prefix_map.get(source_cn, "è‡ªå…»åµ-%")

    with DatabaseConnection() as conn:
        if not conn:
            return 0
        with conn.cursor() as cur:
            cur.execute("""
                SELECT COALESCE(SUM(total_frog), 0)
                FROM t_batch_sorting_record
                WHERE batch_no LIKE %s
            """, (pattern,))
            return int(cur.fetchone()[0])
@st.cache_data(ttl=10, show_spinner=False)
def get_frog_pools(pool_type=None, skin_type=None, purpose=None):
    try:
        base_sql = """
        SELECT
            p.pool_code,
            p.pool_type,
            p.skin_type,
            p.max_capacity,
            p.remark,
            COALESCE(SUM(i.quantity), 0) as current_qty,
            (p.max_capacity - COALESCE(SUM(i.quantity), 0)) as free_space
        FROM t_frog_pool p
        LEFT JOIN t_frog_inventory i ON p.pool_code = i.pool_area
        WHERE 1=1
        """
        params = []
        if purpose == "sale":
            base_sql += """
            AND p.pool_type IN ('ä¸‰å¹´è›™','å››å¹´è›™','äº”å¹´è›™','ç§è›™','è¯•éªŒè›™')
            """
        elif purpose == "year":
            base_sql += " AND p.pool_type IN ('ä¸‰å¹´è›™','å››å¹´è›™','äº”å¹´è›™','ç§è›™','è¯•éªŒè›™') "
        else:
            if pool_type:
                base_sql += " AND p.pool_type = %s"
                params.append(pool_type)
            if skin_type:
                base_sql += " AND p.skin_type = %s"
                params.append(skin_type)
        base_sql += " GROUP BY p.pool_code, p.pool_type, p.skin_type, p.max_capacity, p.remark ORDER BY p.pool_code"
        
        # ğŸ‘‡ å…³é”®ä¿®å¤ï¼šåªæœ‰æœ‰å‚æ•°æ—¶æ‰ä¼  params
        if params:
            df = pd.read_sql(base_sql, engine, params=tuple(params))
        else:
            df = pd.read_sql(base_sql, engine)
            
        if not df.empty:
            df = df.rename(columns={
                'pool_code': 'æ± ç¼–å·',
                'pool_type': 'æ¥æº/å¹´é™',
                'skin_type': 'çš®å‹',
                'max_capacity': 'æœ€å¤§å®¹é‡',
                'current_qty': 'å½“å‰æ•°é‡',
                'free_space': 'å‰©ä½™ç©ºé—´',
                'remark': 'å¤‡æ³¨'
            })
        return df
    except Exception as e:
        st.error(f"æŸ¥è¯¢æˆè›™æ± å¤±è´¥: {e}")
        return pd.DataFrame(columns=['æ± ç¼–å·', 'æ¥æº/å¹´é™', 'çš®å‹', 'æœ€å¤§å®¹é‡', 'å½“å‰æ•°é‡', 'å‰©ä½™ç©ºé—´'])

@st.cache_data(show_spinner=False)
def get_sales_statistics(start_date=None, end_date=None, group_by="day"):
    """
    è·å–é”€å”®ç»Ÿè®¡ä¿¡æ¯
    group_by: 'day'æŒ‰å¤©, 'month'æŒ‰æœˆ, 'source'æŒ‰æ¥æº, 'type'æŒ‰è›™ç±»å‹
    """
    try:
        sql = """
            SELECT 
                b.related_entity_id frog_type_code,
                t.description frog_type,
                SUM(b.operation_value) total_sold,
                DATE_TRUNC(%s, b.operation_time) as period,
                b.remarks,
                b.operation_time
            FROM t_business_behavior_record b
            JOIN t_frog_type_dict t ON b.related_entity_id = t.type_code
            WHERE b.behavior_type = 'é”€å”®æˆè›™'
        """
        params = [group_by]
        
        if start_date:
            sql += " AND b.operation_time >= %s"
            params.append(start_date)
        if end_date:
            sql += " AND b.operation_time <= %s"
            params.append(end_date)
            
        sql += " GROUP BY frog_type_code, frog_type, period, b.remarks, b.operation_time"
        sql += " ORDER BY period DESC, total_sold DESC"
        
        df = pd.read_sql(sql, engine, params=tuple(params))
        
        # æå–æ¥æºæ± åŒºä¿¡æ¯
        def extract_source_pool(remark):
            if pd.isna(remark) or not isinstance(remark, str):
                return 'æœªçŸ¥'
            if 'ä»' in remark and 'é”€å”®' in remark:
                # æ ¼å¼: "ä» è‡ªå…»åµç»†çš®å•†å“è›™æ± -001 é”€å”®"
                parts = remark.split(' ')
                return parts[1] if len(parts) > 1 else 'æœªçŸ¥'
            return 'æœªçŸ¥'
        
        if not df.empty:
            df['æ¥æºæ± åŒº'] = df['remarks'].apply(extract_source_pool)
            df['é”€å”®æ—¥æœŸ'] = df['operation_time'].dt.date
            df['é”€å”®æ—¶é—´'] = df['operation_time'].dt.time
            
        return df
        
    except Exception as e:
        st.error(f"è·å–é”€å”®ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()
@st.cache_data(ttl=30, show_spinner=False)
def get_pool_source_and_skin(pool_code: str):
    """
    é€šè¿‡æŸ¥è¯¢æœ€è¿‘ä¸€æ¬¡ã€Œæˆè›™å†åˆ†ç±»ã€è¡Œä¸ºï¼Œåæ¨è¯¥å¹´é™æ± çš„æ¥æºå’Œçš®å‹
    é€‚ç”¨äºï¼šä¸‰å¹´è›™æ± -001, å››å¹´è›™æ± -001 ç­‰
    è¿”å›: (source, skin) ä¾‹å¦‚ ("è‡ªå…»åµ", "ç»†çš®")
    """
    with DatabaseConnection() as conn:
        if not conn:
            return "æœªçŸ¥", "æœªçŸ¥"
        with conn.cursor() as cur:
            # æŸ¥è¯¢æœ€è¿‘ä¸€æ¬¡å‘è¯¥æ± çš„å†åˆ†ç±»è®°å½•ï¼ˆé€šè¿‡ remarks ä¸­çš„æ¥æºæ± ï¼‰
            cur.execute("""
                SELECT remarks
                FROM t_business_behavior_record
                WHERE behavior_type = 'æˆè›™å†åˆ†ç±»'
                  AND remarks LIKE %s
                ORDER BY operation_time DESC
                LIMIT 1
            """, (f'%{pool_code}%',))
            row = cur.fetchone()
            if not row:
                return "æœªçŸ¥", "æœªçŸ¥"
            remarks = row[0]
            # æ ¼å¼: "ä» è‡ªå…»åµç»†çš®æˆè›™æ± -001 æ‹†åˆ† 15 åª"
            if remarks.startswith("ä» ") and " æ‹†åˆ† " in remarks:
                source_pool = remarks.split(" ")[1]
                if "è‡ªå…»åµ" in source_pool:
                    source = "è‡ªå…»åµ"
                    skin = "ç»†çš®" if "ç»†çš®" in source_pool else "ç²—çš®"
                elif "å¤–è´­èŒèšª" in source_pool:
                    source = "å¤–è´­èŒèšª"
                    skin = "ç»†çš®" if "ç»†çš®" in source_pool else "ç²—çš®"
                elif "å¤–è´­å¹¼è›™" in source_pool:
                    source = "å¤–è´­å¹¼è›™"
                    skin = "ç»†çš®" if "ç»†çš®" in source_pool else "ç²—çš®"
                elif "å¤–è´­æˆè›™" in source_pool:
                    source = "å¤–è´­æˆè›™"
                    skin = "ç»†çš®" if "ç»†çš®" in source_pool else "ç²—çš®"
                else:
                    source, skin = "æœªçŸ¥", "æœªçŸ¥"
                return source, skin
            return "æœªçŸ¥", "æœªçŸ¥"
# ----------------------------- å¤šåª’ä½“æº¯æºï¼šæœ¬åœ°å­˜å‚¨ï¼ˆè°ƒè¯•ç‰ˆï¼‰ ----------------------------- #
import os, stat
from pathlib import Path
import streamlit as st

# 1. ç»Ÿä¸€è·¯å¾„ï¼šä¿è¯è¯»å†™éƒ½åŸºäº MEDIA_ROOT ç»å¯¹è·¯å¾„
SCRIPT_DIR = Path(__file__).parent.resolve()
MEDIA_ROOT = SCRIPT_DIR / "media"
MEDIA_ROOT.mkdir(exist_ok=True)
# 2. ä¿è¯ç›®å½•å¯å†™ï¼ˆLinux/Docker åœºæ™¯ï¼‰
try:
    os.chmod(MEDIA_ROOT, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)
except Exception as e:
    st.warning(f"[DEBUG] ä¿®æ”¹ media ç›®å½•æƒé™å¤±è´¥ï¼š{e}")

def save_uploaded_media(uploaded_files, record_id: str, record_type: str,
                        pool_no: str = None, batch_no: str = None,
                        source_override: str = None) -> list:
    """
    ä¿å­˜ä¸Šä¼ çš„å¤šåª’ä½“æ–‡ä»¶åˆ°æœ¬åœ°ï¼Œè¿”å›ç›¸å¯¹ MEDIA_ROOT çš„è·¯å¾„åˆ—è¡¨
    æ–‡ä»¶åé‡‡ç”¨ä¸­æ–‡å¯è¯»æ¨¡æ¿ï¼Œæ— ç©ºæ ¼ã€æ— ç‰¹æ®Šç¬¦å·
    """
    if not uploaded_files:
        return []

    # ä¸šåŠ¡ç¯èŠ‚ä¸­æ–‡æ˜ å°„
    stage_ch = {
        "batch_input": "æ‰¹æ¬¡æŠ•å…¥",
        "sorting": "åˆ†æ‹£",
        "reclass": "å†åˆ†ç±»",
        "sale": "é”€å”®",
        "feeding": "å–‚é£Ÿ",
        "purchase": "é‡‡è´­",
        "batch_complete": "æ‰¹æ¬¡å®Œæˆ",
        "direct_input": "å¤–è´­å…¥åº“"
    }
    # æ¥æºä¸­æ–‡æ˜ å°„ï¼ˆä»…ä½œ fallbackï¼‰
    source_ch = {
        "batch_input": "è‡ªå…»åµ",
        "sorting": "å¤–è´­èŒèšª",
        "reclass": "è‡ªå…»åµ",
        "sale": "å¤–è´­å¹¼è›™",
        "feeding": "è‡ªå…»åµ",
        "purchase": "é€šç”¨",
        "batch_complete": "è‡ªå…»åµ",
        "direct_input": "å¤–è´­å¹¼è›™"
    }

    stage = stage_ch.get(record_type, "å…¶ä»–")
    # ğŸ‘‡ å…³é”®ï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ source_overrideï¼ˆå¦‚â€œå¤–è´­èŒèšªâ€ï¼‰ï¼Œå¦åˆ™ç”¨é»˜è®¤æ˜ å°„
    source = source_override if source_override is not None else source_ch.get(record_type, "é€šç”¨")

    # ä¸»å¯¹è±¡ï¼šä¼˜å…ˆæ± å·ï¼Œå…¶æ¬¡æ‰¹æ¬¡å·ï¼Œå¦åˆ™ç”¨ record_id å‰ 8 ä½
    main_obj = (pool_no or batch_no or record_id[:8]).replace("-", "_")

    date_str = datetime.now().strftime("%Y%m%d")
    time_str = datetime.now().strftime("%H%M")

    # æ„å»ºä¿å­˜ç›®å½•
    save_dir = MEDIA_ROOT / record_type / str(record_id)
    save_dir.mkdir(parents=True, exist_ok=True)
    os.chmod(save_dir, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)

    saved_paths = []
    for i, file in enumerate(uploaded_files):
        ext = file.name.split('.')[-1].lower()
        # ä¸­æ–‡æ–‡ä»¶åï¼šç¯èŠ‚_æ¥æº_æ± å¯¹è±¡_æ‰¹æ¬¡ç‰‡æ®µ_æ—¥æœŸ_æ—¶é—´_åºå·
        safe_name = f"{stage}_æ¥æº{source}_æ± {main_obj}_æ‰¹æ¬¡{record_id[:8]}_æ—¥æœŸ{date_str}_æ—¶é—´{time_str}_åºå·{i:02d}.{ext}"
        file_path = save_dir / safe_name
        with open(file_path, "wb") as f:
            f.write(file.getbuffer())
        saved_paths.append(str(file_path.relative_to(MEDIA_ROOT)))

    return saved_paths

def render_media_traceability():
    from pathlib import Path
    from datetime import datetime, timedelta
    import re
    st.header("ğŸ” å¤šåª’ä½“æº¯æº")
    st.markdown("æŒ‰æ‰¹æ¬¡ã€æ“ä½œç±»å‹æˆ–æ—¥æœŸæŸ¥è¯¢ç°åœºå›¾ç‰‡/è§†é¢‘")

    col1, col2 = st.columns(2)
    with col1:
        record_type = st.selectbox("æ“ä½œç±»å‹", [
            "å…¨éƒ¨", "æ‰¹æ¬¡æŠ•å…¥", "åˆ†æ‰¹åˆ†æ‹£", "æˆè›™å†åˆ†ç±»", "é”€å”®æˆè›™", "å–‚é£Ÿ", "é‡‡è´­ç‰©èµ„"
        ])
    with col2:
        date_range = st.date_input("æ—¥æœŸèŒƒå›´", [datetime.now() - timedelta(days=7), datetime.now()])

    # æ˜ å°„ä¸­æ–‡åˆ°è‹±æ–‡ç›®å½•å
    type_map = {
        "å…¨éƒ¨": None,
        "æ‰¹æ¬¡æŠ•å…¥": "batch_input",
        "åˆ†æ‰¹åˆ†æ‹£": "sorting",
        "æˆè›™å†åˆ†ç±»": "reclass",
        "é”€å”®æˆè›™": "sale",
        "å–‚é£Ÿ": "feeding",
        "é‡‡è´­ç‰©èµ„": "purchase",
        "å¤–è´­å¹¼è›™å…¥åº“": "direct_input",
        "æ‰¹æ¬¡å®Œæˆ": "batch_complete"
    }
    target_dir = type_map.get(record_type)

    base_path = MEDIA_ROOT
    media_files = []

    if base_path.exists():
        for record_type_dir in base_path.iterdir():
            if not record_type_dir.is_dir():
                continue
            if target_dir and record_type_dir.name != target_dir:
                continue
            for record_id_dir in record_type_dir.iterdir():
                if not record_id_dir.is_dir():
                    continue
                for file in record_id_dir.iterdir():
                    if file.is_file():
                        mtime = datetime.fromtimestamp(file.stat().st_mtime)
                        if date_range[0] <= mtime.date() <= date_range[1]:
                            media_files.append(file)

    if not media_files:
        st.info("æœªæ‰¾åˆ°å¤šåª’ä½“æ–‡ä»¶")
        return

    # æŒ‰ä¿®æ”¹æ—¶é—´å€’åº
    media_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)

    # è§£ææ–‡ä»¶å…ƒä¿¡æ¯
    parsed_files = []
    for fp in media_files:
        filename = fp.name
        info = {
            "path": fp,
            "filename": filename,
            "suffix": fp.suffix.lower(),
            "mtime": datetime.fromtimestamp(fp.stat().st_mtime),
            "desc": f"ğŸ“ {filename}",
            "pool_no": "æœªçŸ¥",
            "stage": "æœªçŸ¥",
            "source": "æœªçŸ¥",
            "time_str": "æœªçŸ¥æ—¶é—´"
        }
        try:
            match = re.search(
                r'(.+)_æ¥æº(.+)_æ± ([^_]+)_æ‰¹æ¬¡[^_]*_æ—¥æœŸ(\d{8})_æ—¶é—´(\d{4})',
                filename
            )
            if match:
                stage, source, pool_raw, date_str, time_str = match.groups()
                pool_no = pool_raw.replace('_', '-')
                try:
                    dt = datetime.strptime(date_str + time_str, "%Y%m%d%H%M")
                    time_formatted = dt.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
                except:
                    time_formatted = f"{date_str[:4]}å¹´{date_str[4:6]}æœˆ{date_str[6:8]}æ—¥ {time_str[:2]}:{time_str[2:4]}"
                info.update({
                    "stage": stage,
                    "source": source,
                    "pool_no": pool_no,
                    "time_str": time_formatted,
                    "desc": f"ğŸ“¸ {time_formatted} åœ¨ **{pool_no}** æ± è¿›è¡Œ **{stage}ï¼ˆæ¥æºï¼š{source}ï¼‰**"
                })
        except Exception:
            pass
        parsed_files.append(info)

    # ===== æ–°å¢ï¼šç¼©ç•¥å›¾ç½‘æ ¼å±•ç¤º =====
    st.subheader("ğŸ“¸ å¤šåª’ä½“ç¼©ç•¥å›¾")
    cols = st.columns(4)  # æ¯è¡Œ4ä¸ªç¼©ç•¥å›¾
    for idx, item in enumerate(parsed_files):
        col = cols[idx % 4]
        suffix = item["suffix"]
        with col:
            # ç¼©ç•¥å›¾ç‚¹å‡»äº‹ä»¶ï¼šé€šè¿‡æŒ‰é’®è®¾ç½® session_state
            if suffix in ['.jpg', '.jpeg', '.png']:
                try:
                    col.image(str(item["path"]), use_container_width=True)
                except:
                    col.write("ğŸ–¼ï¸ å›¾ç‰‡åŠ è½½å¤±è´¥")
            elif suffix in ['.mp4', '.mov']:
                thumb_path = MEDIA_ROOT / "video_thumb.png"
                if thumb_path.exists():
                    col.image(str(thumb_path), use_container_width=True)
                else:
                    col.image("https://via.placeholder.com/160x120/333333/FFFFFF?text=  â–¶+è§†é¢‘", use_container_width=True)
            else:
                col.image("https://via.placeholder.com/150?text=  ğŸ“„+æ–‡ä»¶", use_container_width=True)

            # å°å­—æè¿°ï¼ˆå¯é€‰ï¼‰
            col.caption(f"{item['pool_no']} | {item['stage']}")
            
            # ç‚¹å‡»æŒ‰é’®è§¦å‘é¢„è§ˆ
            if col.button("ğŸ” æŸ¥çœ‹", key=f"btn_{idx}", use_container_width=True):
                st.session_state["preview_media"] = item

    st.divider()

    # ===== é¢„è§ˆåŒº =====
    if "preview_media" in st.session_state:
        item = st.session_state["preview_media"]
        st.subheader("ğŸ“Œ æ–‡ä»¶è¯¦æƒ…")
        st.markdown(item["desc"])
        try:
            if item["suffix"] in ['.jpg', '.jpeg', '.png']:
                st.image(str(item["path"]), width=600)
            elif item["suffix"] in ['.mp4', '.mov']:
                st.video(str(item["path"]))
            with open(item["path"], "rb") as f:
                st.download_button("â¬‡ï¸ ä¸‹è½½åŸæ–‡ä»¶", data=f, file_name=item["filename"])
        except Exception as e:
            st.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥ï¼š{e}")
# ----------------------------- ä¸šåŠ¡æ“ä½œå‡½æ•°ï¼ˆå·²æ”¯æŒ media_filesï¼‰ ----------------------------- #
def create_batch(pool_no, input_type, initial_input, input_unit, input_time, operator, media_files=None):
    try:
        with DatabaseConnection() as conn:
            if not conn:
                return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            with conn.cursor() as cur:
                timestamp = input_time.strftime('%Y%m%d_%H%M%S')
                # ä¸­æ–‡æ¥æºæ˜ å°„
                source_cn = {
                    "è‡ªå…»åµ": "è‡ªå…»åµ",
                    "å¤–è´­èŒèšª": "å¤–è´­èŒèšª",
                    "å¤–è´­å¹¼è›™": "å¤–è´­å¹¼è›™",
                    "å¤–è´­æˆè›™": "å¤–è´­æˆè›™",
                }.get(input_type, "å…¶ä»–")

                # æ–°æ‰¹å·ï¼šæ¥æº-æœˆæ—¥-æ—¶åˆ†-æ± å·
                mmdd = input_time.strftime("%m%d")
                hhmm = input_time.strftime("%H%M")
                batch_no = f"{source_cn}-{mmdd}-{hhmm}-{pool_no}"
                cur.execute("BEGIN")
                cur.execute("""INSERT INTO t_incubation_batch
                               (batch_no, pool_no, input_type, initial_input, input_unit, input_time, batch_status)
                               VALUES (%s, %s, %s, %s, %s, %s, 'ä½¿ç”¨ä¸­')""",
                            (batch_no, pool_no, input_type, initial_input, input_unit, input_time))
                cur.execute("""UPDATE t_incubation_pool
                               SET current_status = 'ä½¿ç”¨ä¸­', current_batch_no = %s, update_time = CURRENT_TIMESTAMP
                               WHERE pool_no = %s""", (batch_no, pool_no))
                if cur.rowcount == 0:
                    conn.rollback()
                    return False, f"âŒ ä¸¥é‡é”™è¯¯ï¼šæœªèƒ½æ›´æ–°æ± å­ {pool_no} çš„çŠ¶æ€ã€‚"
                record_id = str(uuid.uuid4())
                cur.execute("""INSERT INTO t_business_behavior_record
                               (record_id, behavior_type, related_batch_no, operation_value, operation_time, operator, remarks)
                               VALUES (%s, 'æ‰¹æ¬¡æŠ•å…¥', %s, %s, %s, %s, %s)""",
                            (record_id, batch_no, initial_input, input_time, operator.strip(),
                             f"{input_type}æŠ•å…¥{initial_input}{input_unit}åˆ°{pool_no}"))
                conn.commit()
                if media_files:
                    # ğŸ‘‡ å…³é”®ï¼šå°† input_typeï¼ˆå¦‚â€œå¤–è´­èŒèšªâ€ï¼‰ä½œä¸º source_override ä¼ å…¥
                    save_uploaded_media(media_files, record_id, "batch_input", pool_no=pool_no, source_override=input_type)
                fetch_incubation_pools.clear()
                fetch_active_batches.clear()
                return True, f"âœ… æ‰¹æ¬¡åˆ›å»ºæˆåŠŸ: {batch_no}"
    except Exception as e:
        return False, f"âŒ åˆ›å»ºæ‰¹æ¬¡å¤±è´¥: {e}"
    
def record_sorting(batch_no, round_no, sorting_time, total_frog, frog_details: dict, operator, pool_area="æ€»æˆè›™æ± ", media_files=None):
    try:
        with DatabaseConnection() as conn:
            if not conn:
                return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            with conn.cursor() as cur:
                cur.execute("BEGIN")
                record_id = str(uuid.uuid4())
                cur.execute("""
                    INSERT INTO t_batch_sorting_record
                    (record_id, batch_no, round_no, sorting_time, total_frog, frog_detail, operator)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (record_id, batch_no, round_no, sorting_time, total_frog,
                      json.dumps(frog_details),
                      operator.strip()))
                cur.execute("""
                    UPDATE t_incubation_batch
                       SET total_sorted_frog = total_sorted_frog + %s,
                           update_time = CURRENT_TIMESTAMP
                     WHERE batch_no = %s
                """, (total_frog, batch_no))
                for frog_type, quantity in frog_details.items():
                    cur.execute("""
                        INSERT INTO t_frog_inventory (frog_type_code, quantity, pool_area)
                        VALUES (%s, %s, %s)
                        ON CONFLICT (frog_type_code, pool_area)
                        DO UPDATE SET quantity = t_frog_inventory.quantity + EXCLUDED.quantity,
                                      last_update_time = CURRENT_TIMESTAMP
                    """, (frog_type, quantity, pool_area))
                behavior_id = str(uuid.uuid4())
                cur.execute("""
                    INSERT INTO t_business_behavior_record
                    (record_id, behavior_type, related_batch_no, operation_value, operation_time, operator, remarks)
                    VALUES (%s, 'åˆ†æ‰¹åˆ†æ‹£', %s, %s, %s, %s, %s)
                """, (behavior_id, batch_no, total_frog, sorting_time,
                      operator.strip(), f"ç¬¬{round_no}è½®åˆ†æ‹£åˆ°{pool_area}"))
                conn.commit()
                if media_files:
                    save_uploaded_media(media_files, record_id, "sorting", batch_no=batch_no)
                return True, f"ç¬¬{round_no}è½®åˆ†æ‹£è®°å½•æˆåŠŸ"
    except Exception as e:
        return False, f"è®°å½•åˆ†æ‹£å¤±è´¥: {e}"
def complete_batch(batch_no, complete_time, operator, media_files=None):
    try:
        with DatabaseConnection() as conn:
            if not conn: return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            with conn.cursor() as cur:
                cur.execute("SELECT pool_no FROM t_incubation_batch WHERE batch_no = %s", (batch_no,))
                result = cur.fetchone()
                if not result: return False, "æ‰¹æ¬¡ä¸å­˜åœ¨"
                pool_no = result[0]
                cur.execute("BEGIN")
                cur.execute("""UPDATE t_incubation_batch
                               SET batch_status = 'å·²å®Œæˆ', complete_time = %s, update_time = CURRENT_TIMESTAMP
                               WHERE batch_no = %s""", (complete_time, batch_no))
                cur.execute("""UPDATE t_incubation_pool
                               SET current_status = 'ç©ºé—²', current_batch_no = NULL, update_time = CURRENT_TIMESTAMP
                               WHERE pool_no = %s""", (pool_no,))
                record_id = str(uuid.uuid4())
                cur.execute("""INSERT INTO t_business_behavior_record
                               (record_id, behavior_type, related_batch_no, operation_time, operator, remarks)
                               VALUES (%s, 'æ‰¹æ¬¡å®Œæˆ', %s, %s, %s, 'æ‰¹æ¬¡ç»“æŸï¼Œå­µåŒ–æ± å·²ç©ºé—²')""",
                            (record_id, batch_no, complete_time, operator.strip()))
                conn.commit()
                if media_files:
                    save_uploaded_media(media_files, record_id, "batch_complete", batch_no=batch_no)
                fetch_incubation_pools.clear()
                return True, f"æ‰¹æ¬¡{batch_no}å·²æ ‡è®°ä¸ºå®Œæˆ"
    except Exception as e:
        return False, f"å®Œæˆæ‰¹æ¬¡å¤±è´¥: {e}"
def record_material_purchase(material_type, quantity, purchase_time, operator, remarks="", 
                             frog_type=None, target_pool=None, media_files=None):
    try:
        with DatabaseConnection() as conn:
            if not conn: return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            with conn.cursor() as cur:
                cur.execute("BEGIN")
                cur.execute("SELECT id FROM t_material_inventory WHERE material_type_code = %s", (material_type,))
                inventory_id = cur.fetchone()
                if inventory_id:
                    cur.execute("""UPDATE t_material_inventory
                                   SET remaining_quantity = remaining_quantity + %s, last_update_time = CURRENT_TIMESTAMP
                                   WHERE id = %s""", (quantity, inventory_id[0]))
                else:
                    cur.execute("""INSERT INTO t_material_inventory (material_type_code, remaining_quantity)
                                   VALUES (%s, %s)""", (material_type, quantity))
                if material_type in ["TADPOLE", "YOUNG_FROG", "ADULT_FROG"]:
                    if not frog_type or not target_pool:
                        return False, "è›™ç±»é‡‡è´­å¿…é¡»æŒ‡å®šè›™ç±»å‹å’Œç›®æ ‡æ± åŒº"
                    cur.execute("""
                        INSERT INTO t_frog_inventory (frog_type_code, quantity, pool_area)
                        VALUES (%s, %s, %s)
                        ON CONFLICT (frog_type_code, pool_area)
                        DO UPDATE SET quantity = t_frog_inventory.quantity + EXCLUDED.quantity,
                                      last_update_time = CURRENT_TIMESTAMP
                    """, (frog_type, quantity, target_pool))
                record_id = str(uuid.uuid4())
                cur.execute("""INSERT INTO t_business_behavior_record
                               (record_id, behavior_type, related_entity_id, operation_value, operation_time, operator, remarks)
                               VALUES (%s, 'é‡‡è´­ç‰©èµ„', %s, %s, %s, %s, %s)""",
                            (record_id, material_type, quantity, purchase_time, operator.strip(), remarks or 'é‡‡è´­ç‰©èµ„'))
                conn.commit()
                if media_files:
                    save_uploaded_media(media_files, record_id, "purchase")
                return True, f"ç‰©èµ„é‡‡è´­è®°å½•æˆåŠŸ"
    except Exception as e:
        return False, f"è®°å½•é‡‡è´­å¤±è´¥: {e}"
def record_feeding(material_type, quantity, feeding_time, target, operator, media_files=None):
    try:
        with DatabaseConnection() as conn:
            if not conn: return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            with conn.cursor() as cur:
                cur.execute("SELECT remaining_quantity FROM t_material_inventory WHERE material_type_code = %s", (material_type,))
                result = cur.fetchone()
                if not result or result[0] < quantity:
                    return False, "ç‰©èµ„åº“å­˜ä¸è¶³"
                cur.execute("BEGIN")
                cur.execute("""UPDATE t_material_inventory
                               SET remaining_quantity = remaining_quantity - %s, last_update_time = CURRENT_TIMESTAMP
                               WHERE material_type_code = %s""", (quantity, material_type))
                record_id = str(uuid.uuid4())
                cur.execute("""INSERT INTO t_business_behavior_record
                               (record_id, behavior_type, related_entity_id, operation_value, operation_time, operator, remarks)
                               VALUES (%s, 'å–‚é£Ÿ', %s, %s, %s, %s, %s)""",
                            (record_id, material_type, quantity, feeding_time, operator.strip(), f"å–‚é£Ÿå¯¹è±¡: {target}"))
                conn.commit()
                if media_files:
                    save_uploaded_media(media_files, record_id, "feeding")
                return True, f"å–‚é£Ÿè®°å½•æˆåŠŸ"
    except Exception as e:
        return False, f"è®°å½•å–‚é£Ÿå¤±è´¥: {e}"
# åŒæ—¶éœ€è¦æ›´æ–°é”€å”®å‡½æ•°ï¼Œæ”¯æŒä»å…·ä½“å•†å“è›™æ± é”€å”®
def record_frog_sale_from_pool(frog_type, quantity, sale_time, operator, pool_area, remarks="", media_files=None):
    """
    ä¼˜åŒ–ç‰ˆï¼šæ”¯æŒä»å…·ä½“å•†å“è›™æ± é”€å”®ï¼Œç¡®ä¿æº¯æº
    """
    try:
        with DatabaseConnection() as conn:
            if not conn: 
                return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            
            with conn.cursor() as cur:
                # æ£€æŸ¥åº“å­˜
                cur.execute("""SELECT id, quantity FROM t_frog_inventory
                               WHERE frog_type_code = %s AND pool_area = %s""", 
                           (frog_type, pool_area))
                result = cur.fetchone()
                
                if not result or result[1] < quantity:
                    return False, f"{pool_area} ä¸­ {frog_type} åº“å­˜ä¸è¶³"
                
                inventory_id = result[0]
                
                cur.execute("BEGIN")
                
                # æ‰£å‡åº“å­˜
                cur.execute("""UPDATE t_frog_inventory
                               SET quantity = quantity - %s, last_update_time = CURRENT_TIMESTAMP
                               WHERE id = %s""", (quantity, inventory_id))
                
                # è®°å½•é”€å”®è¡Œä¸ºï¼ŒåŒ…å«è¯¦ç»†çš„æ± åŒºä¿¡æ¯ç”¨äºæº¯æº
                record_id = str(uuid.uuid4())
                cur.execute("""INSERT INTO t_business_behavior_record
                               (record_id, behavior_type, related_entity_id, operation_value, operation_time, operator, remarks)
                               VALUES (%s, 'é”€å”®æˆè›™', %s, %s, %s, %s, %s)""",
                          (record_id, frog_type, quantity, sale_time, operator.strip(), remarks))
                
                conn.commit()
                
                if media_files:
                    save_uploaded_media(media_files, record_id, "sale", pool_no=pool_area)
                
                return True, f"âœ… æˆåŠŸä» {pool_area} é”€å”® {quantity} åª {frog_type}"
                
    except Exception as e:
        return False, f"è®°å½•é”€å”®å¤±è´¥: {e}"
def record_direct_frog_input(frog_type, quantity, input_time, operator, target_pool_area, remarks="", media_files=None):
    try:
        with DatabaseConnection() as conn:
            if not conn:
                return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            with conn.cursor() as cur:
                cur.execute("BEGIN")
                cur.execute("""
                    INSERT INTO t_frog_inventory (frog_type_code, quantity, pool_area)
                    VALUES (%s, %s, %s)
                    ON CONFLICT (frog_type_code, pool_area)
                    DO UPDATE SET quantity = t_frog_inventory.quantity + EXCLUDED.quantity,
                                  last_update_time = CURRENT_TIMESTAMP
                """, (frog_type, quantity, target_pool_area))
                record_id = str(uuid.uuid4())
                cur.execute("""
                    INSERT INTO t_business_behavior_record
                    (record_id, behavior_type, related_entity_id, operation_value, operation_time, operator, remarks)
                    VALUES (%s, 'å¤–è´­å¹¼è›™å…¥åº“', %s, %s, %s, %s, %s)
                """, (record_id, frog_type, quantity, input_time, operator.strip(), remarks))
                conn.commit()
                if media_files:
                    save_uploaded_media(media_files, record_id, "direct_input", pool_no=target_pool_area)
                return True, f"æˆåŠŸå°† {quantity} åªå¤–è´­å¹¼è›™å…¥åº“åˆ° {target_pool_area}"
    except Exception as e:
        return False, f"è®°å½•å¤–è´­å¹¼è›™å…¥åº“å¤±è´¥: {e}"
def record_frog_reclassification_to_target(from_pool_area, to_details: dict, reclass_time, operator, media_files=None):
    """
    ä¼˜åŒ–ç‰ˆï¼šæ ¹æ®æ¥æºæ± åŒºè‡ªåŠ¨åˆ†é…åˆ°å¯¹åº”çš„å•†å“è›™æ± 
    """
    try:
        with DatabaseConnection() as conn:
            if not conn: 
                return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            
            with conn.cursor() as cur:
                cur.execute("BEGIN")
                
                # è®¡ç®—æ€»éœ€æ±‚é‡
                total_requested = sum(to_details.values())
                
                # æ£€æŸ¥åº“å­˜æ˜¯å¦è¶³å¤Ÿ
                cur.execute("SELECT COALESCE(SUM(quantity), 0) FROM t_frog_inventory WHERE pool_area = %s", (from_pool_area,))
                total_available = cur.fetchone()[0] or 0
                
                if total_available < total_requested:
                    return False, f"åº“å­˜ä¸è¶³ï¼{from_pool_area} å½“å‰åªæœ‰ {int(total_available)} åª"
                
                # ä»åŸæ± åŒºæ‰£é™¤
                cur.execute("UPDATE t_frog_inventory SET quantity = quantity - %s WHERE pool_area = %s", 
                           (total_requested, from_pool_area))
                
                # è§£ææ¥æºä¿¡æ¯ï¼Œæ„å»ºç›®æ ‡æ± åŒºæ˜ å°„
                if "ç»†çš®" in from_pool_area:
                    skin_type = "ç»†çš®"
                elif "ç²—çš®" in from_pool_area:
                    skin_type = "ç²—çš®"
                else:
                    skin_type = "æœªçŸ¥"
                
                # æ ¹æ®æ¥æºæ± åŒºç¡®å®šæ¥æºç±»å‹
                if "è‡ªå…»åµ" in from_pool_area:
                    source_type = "è‡ªå…»åµ"
                elif "å¤–è´­èŒèšª" in from_pool_area:
                    source_type = "å¤–è´­èŒèšª"
                elif "å¤–è´­å¹¼è›™" in from_pool_area:
                    source_type = "å¤–è´­å¹¼è›™"
                elif "å¤–è´­æˆè›™" in from_pool_area:
                    source_type = "å¤–è´­æˆè›™"
                else:
                    source_type = "æœªçŸ¥"
                
                for frog_type, qty in to_details.items():
                    if qty <= 0:
                        continue
                        
                    # æ ¹æ®è›™ç±»å‹ç¡®å®šç›®æ ‡æ± åŒº
                    if frog_type.startswith("SP_"):  # å•†å“è›™
                        # æ„å»ºå¯¹åº”çš„å•†å“è›™æ± åç§°
                        target_pool_area = f"{source_type}{skin_type}å•†å“è›™æ± -001"
                        
                        # æ£€æŸ¥ç›®æ ‡æ± æ˜¯å¦å­˜åœ¨
                        cur.execute("SELECT COUNT(*) FROM t_frog_pool WHERE pool_code = %s", (target_pool_area,))
                        if cur.fetchone()[0] == 0:
                            # å¦‚æœæ± å­ä¸å­˜åœ¨ï¼Œä½¿ç”¨é€šç”¨å•†å“è›™æ± 
                            target_pool_area = "å•†å“è›™æ± "
                            
                    elif frog_type.startswith("ZB_"):  # ç§è›™
                        target_pool_area = "ç§è›™æ± "
                    elif frog_type.startswith("SY_"):  # è¯•éªŒè›™
                        target_pool_area = "è¯•éªŒè›™æ± "
                    else:
                        target_pool_area = "é»˜è®¤æ± åŒº"
                    
                    # æ’å…¥æˆ–æ›´æ–°ç›®æ ‡æ± åŒºåº“å­˜
                    cur.execute("""
                        INSERT INTO t_frog_inventory (frog_type_code, quantity, pool_area)
                        VALUES (%s, %s, %s)
                        ON CONFLICT (frog_type_code, pool_area)
                        DO UPDATE SET quantity = t_frog_inventory.quantity + EXCLUDED.quantity,
                                      last_update_time = CURRENT_TIMESTAMP
                    """, (frog_type, qty, target_pool_area))
                
                # è®°å½•ä¸šåŠ¡è¡Œä¸º
                record_id = str(uuid.uuid4())
                cur.execute("""
                    INSERT INTO t_business_behavior_record
                    (record_id, behavior_type, operation_value, operation_time, operator, remarks)
                    VALUES (%s, 'æˆè›™å†åˆ†ç±»', %s, %s, %s, %s)
                """, (record_id, total_requested, reclass_time, operator.strip(), 
                      f"ä» {from_pool_area} ç»†åˆ†åˆ°å¯¹åº”å•†å“è›™æ± "))
                
                conn.commit()
                
                if media_files:
                    save_uploaded_media(media_files, record_id, "reclass", pool_no=from_pool_area)
                
                return True, f"æˆåŠŸä» {from_pool_area} åˆ†æ‹£ {total_requested} åªåˆ°å¯¹åº”å•†å“è›™æ± "
                
    except Exception as e:
        return False, f"è®°å½•å†åˆ†ç±»å¤±è´¥: {e}"
def record_inventory_operation(
    item_type: str,
    item_code: str,
    operation: str,
    quantity: float,
    pool_or_warehouse: str = "",
    operation_time: datetime = None,
    operator: str = "admin",
    remarks: str = ""
):
    if not operation_time:
        operation_time = datetime.now()
    try:
        with DatabaseConnection() as conn:
            if not conn:
                return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            with conn.cursor() as cur:
                cur.execute("BEGIN")
                if item_type == "frog":
                    if operation == "ç›˜ç‚¹":
                        cur.execute("""
                            INSERT INTO t_frog_inventory (frog_type_code, quantity, pool_area)
                            VALUES (%s, %s, %s)
                            ON CONFLICT (frog_type_code, pool_area)
                            DO UPDATE SET quantity = EXCLUDED.quantity, last_update_time = CURRENT_TIMESTAMP
                        """, (item_code, quantity, pool_or_warehouse or "é»˜è®¤æ± åŒº"))
                    else:
                        delta = quantity if operation == "å…¥åº“" else -quantity
                        cur.execute("""
                            INSERT INTO t_frog_inventory (frog_type_code, quantity, pool_area)
                            VALUES (%s, %s, %s)
                            ON CONFLICT (frog_type_code, pool_area)
                            DO UPDATE SET quantity = t_frog_inventory.quantity + %s, last_update_time = CURRENT_TIMESTAMP
                        """, (item_code, max(0, delta), pool_or_warehouse or "é»˜è®¤æ± åŒº", delta))
                        cur.execute("SELECT quantity FROM t_frog_inventory WHERE frog_type_code = %s AND pool_area = %s", 
                                   (item_code, pool_or_warehouse or "é»˜è®¤æ± åŒº"))
                        if cur.fetchone()[0] < 0:
                            conn.rollback()
                            return False, "å‡ºåº“æ•°é‡è¶…è¿‡åº“å­˜ï¼"
                else:
                    if operation == "ç›˜ç‚¹":
                        cur.execute("""
                            INSERT INTO t_material_inventory (material_type_code, remaining_quantity)
                            VALUES (%s, %s)
                            ON CONFLICT (material_type_code)
                            DO UPDATE SET remaining_quantity = EXCLUDED.remaining_quantity, last_update_time = CURRENT_TIMESTAMP
                        """, (item_code, quantity))
                    else:
                        delta = quantity if operation == "å…¥åº“" else -quantity
                        cur.execute("""
                            INSERT INTO t_material_inventory (material_type_code, remaining_quantity)
                            VALUES (%s, %s)
                            ON CONFLICT (material_type_code)
                            DO UPDATE SET remaining_quantity = t_material_inventory.remaining_quantity + %s, last_update_time = CURRENT_TIMESTAMP
                        """, (item_code, max(0, delta), delta))
                        cur.execute("SELECT remaining_quantity FROM t_material_inventory WHERE material_type_code = %s", (item_code,))
                        if cur.fetchone()[0] < 0:
                            conn.rollback()
                            return False, "å‡ºåº“æ•°é‡è¶…è¿‡åº“å­˜ï¼"
                behavior_map = {
                    ("frog", "å…¥åº“"): "è¿›é”€å­˜-è›™ç±»å…¥åº“",
                    ("frog", "å‡ºåº“"): "è¿›é”€å­˜-è›™ç±»å‡ºåº“",
                    ("frog", "ç›˜ç‚¹"): "è¿›é”€å­˜-ç›˜ç‚¹",
                    ("material", "å…¥åº“"): "è¿›é”€å­˜-ç‰©èµ„å…¥åº“",
                    ("material", "å‡ºåº“"): "è¿›é”€å­˜-ç‰©èµ„å‡ºåº“",
                }
                behavior_type = behavior_map.get((item_type, operation), "è¿›é”€å­˜-å…¶ä»–")
                cur.execute("""
                    INSERT INTO t_business_behavior_record
                    (record_id, behavior_type, related_entity_id, operation_value, operation_time, operator, remarks)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (str(uuid.uuid4()), behavior_type, item_code, quantity, operation_time, operator, remarks))
                conn.commit()
                return True, f"{operation}æˆåŠŸ"
    except Exception as e:
        return False, f"æ“ä½œå¤±è´¥: {e}"
# ----------------------------- é¡µé¢æ¸²æŸ“ï¼šå››æ¥æºåˆ†ç¦»ç‰ˆ ----------------------------- #
# ----------------------------- é¡µé¢æ¸²æŸ“ï¼šå››æ¥æºåˆ†ç¦»ç‰ˆ ----------------------------- #
def render_operation_module():
    import time
    ts = lambda: str(int(time.time()))  # ç§’çº§æ—¶é—´æˆ³

    st.header("ç°åœºæ“ä½œè®°å½•")
    st.markdown("---")
    operator = st.text_input("æ“ä½œå‘˜", value="admin", key="operator_input")
    if not operator.strip():
        st.warning("è¯·è¾“å…¥æ“ä½œå‘˜å§“å")
        return

    st.markdown("ğŸ“ å½“å‰å­µåŒ–æ± å ç”¨æƒ…å†µï¼ˆä»…ä¾›å‚è€ƒï¼‰")
    pools = fetch_incubation_pools()
    if pools:
        df_pools = pd.DataFrame(pools, columns=["æ± å·", "ä½ç½®", "çŠ¶æ€", "æ‰¹æ¬¡"])
        df_pools["çŠ¶æ€"] = df_pools["çŠ¶æ€"].map({"ç©ºé—²": "ğŸŸ¢ ç©ºé—²", "ä½¿ç”¨ä¸­": "ğŸ”´ ä½¿ç”¨ä¸­"})
        st.dataframe(df_pools, use_container_width=True, hide_index=True)
    else:
        st.info("æš‚æ— å­µåŒ–æ± æ•°æ®")

    tab_egg, tab_tadpole, tab_young, tab_adult = st.tabs([
        "ğŸ£ è‡ªå…»åµæµç¨‹", "ğŸª· å¤–è´­èŒèšªæµç¨‹", "ğŸ¸ å¤–è´­å¹¼è›™æµç¨‹", "ğŸ›’ å¤–è´­æˆè›™æµç¨‹"
    ])

    # ========== 1. è‡ªå…»åµ ==========
    with tab_egg:
        st.subheader("1. æ‰¹æ¬¡æŠ•å…¥ï¼ˆè‡ªå…»åµï¼‰")
        free_pools = fetch_incubation_pools("ç©ºé—²")
        if not free_pools:
            st.warning("æ²¡æœ‰å¯ç”¨çš„ç©ºé—²å­µåŒ–æ± ")
        else:
            with st.form("batch_egg"):
                col1, col2 = st.columns(2)
                with col1:
                    pool_opts = [f"{p[0]} ({p[1]})" for p in free_pools]
                    sel = st.selectbox("é€‰æ‹©å­µåŒ–æ± ", pool_opts)
                    pool_no = sel.split()[0]
                    board = st.number_input("æŠ•å…¥æ¿æ•°ï¼ˆ1æ¿=1000é¢—ï¼‰", min_value=0.0, step=0.1)
                    qty = int(board * 1000)
                with col2:
                    dt = st.date_input("æ—¥æœŸ", datetime.now())
                    tm = st.time_input("æ—¶é—´", datetime.now().time())
                    input_time = datetime.combine(dt, tm)
                uploaded = st.file_uploader(
                    "ğŸ“¸ ä¸Šä¼ ç°åœºå›¾ç‰‡/è§†é¢‘ï¼ˆå¯å¤šé€‰ï¼‰",
                    type=["jpg", "jpeg", "png", "mp4", "mov"],
                    accept_multiple_files=True,
                    key=f"up_egg_batch_{pool_no}"
                )
                if st.form_submit_button("æäº¤") and qty > 0:
                    ok, msg = create_batch(pool_no, "è‡ªå…»åµ", qty, "é¢—", input_time,
                                           operator.strip(), media_files=uploaded)
                    if ok:
                        st.success(msg)
                        st.rerun()
                    else:
                        st.error(msg)

        st.markdown("---")
        # ========== è‡ªå…»åµåˆ†æ‹£éƒ¨åˆ† ==========
        st.subheader("2. åˆ†æ‰¹åˆ†æ‹£ï¼ˆè‡ªå…»åµ â†’ æˆè›™æ± ï¼‰")
        sorted_total = get_sorted_frog_total_by_source("è‡ªå…»åµ")
        st.info(f"ğŸ“Š è‡ªå…»åµæµç¨‹å·²åˆ†æ‹£åˆ°æˆè›™æ± ç´¯è®¡ï¼š**{sorted_total} åª**")

        active = [b for b in fetch_active_batches() if b[2] == "è‡ªå…»åµ"]
        if not active:
            st.info("æš‚æ— è‡ªå…»åµæ´»è·ƒæ‰¹æ¬¡")
        else:
            batch_opts = [f"{b[0]} ({b[1]})" for b in active]
            sel = st.selectbox("é€‰æ‹©æ‰¹æ¬¡", batch_opts)
            batch_no = sel.split()[0]

            # ğŸ‘‡ æŠŠ radio å’Œæ± å­æ¦‚è§ˆç§»åˆ° form å¤–é¢ï¼
            skin = st.radio("çš®å‹", ["ç»†çš®", "ç²—çš®"], horizontal=True, key=f"egg_skin_radio_{batch_no}")

            # å®æ—¶æ˜¾ç¤ºæˆè›™æ± å®¹é‡ï¼ˆä¸ä¾èµ–è¡¨å•æäº¤ï¼‰
            pool_df = get_frog_pools(pool_type='è‡ªå…»åµ', skin_type=skin)
            pool_df = pool_df[~pool_df['æ± ç¼–å·'].str.contains('å•†å“è›™æ± ')] 
            if pool_df.empty:
                st.error('æš‚æ— å¯¹åº”æˆè›™æ± ï¼Œè¯·å…ˆè”ç³»ç®¡ç†å‘˜å»ºæ± ')
            else:
                st.write("ğŸ“ æˆè›™æ± å®¹é‡æ¦‚è§ˆ")
                st.dataframe(pool_df, use_container_width=True)
                full_pools = pool_df[pool_df['å‰©ä½™ç©ºé—´'] <= 0]['æ± ç¼–å·'].tolist()
                if full_pools:
                    st.error(f"æ± å­ {full_pools} å·²æ»¡ 500 åªï¼Œè¯·å…ˆå¢åŠ æ–°æ± å†åˆ†æ‹£ï¼")

            # è¡¨å•å†…åªä¿ç•™è¾“å…¥å’Œæäº¤
            with st.form("sort_egg"):
                col1, col2 = st.columns(2)
                with col1:
                    with DatabaseConnection() as conn:
                        with conn.cursor() as cur:
                            cur.execute("SELECT COALESCE(MAX(round_no),0)+1 FROM t_batch_sorting_record WHERE batch_no=%s", (batch_no,))
                            rnd = cur.fetchone()[0]
                    total = st.number_input("åˆ†æ‹£æ•°é‡ï¼ˆåªï¼‰", min_value=1)
                    avg_w = st.number_input("å¹³å‡é‡é‡ï¼ˆå…‹ï¼‰", min_value=0.1, value=25.0)
                with col2:
                    dt = st.date_input("åˆ†æ‹£æ—¥æœŸ", datetime.now(), key="sort_egg_d")
                    tm = st.time_input("åˆ†æ‹£æ—¶é—´", datetime.now().time(), key="sort_egg_t")

                # ç›®æ ‡æ± é€‰æ‹©ï¼ˆåŸºäºå·²åŠ è½½çš„ pool_dfï¼‰
                if not pool_df.empty and not full_pools:
                    target_pool = st.selectbox(
                        "è¯·é€‰æ‹©ç›®æ ‡æˆè›™æ± ",
                        pool_df['æ± ç¼–å·'].tolist(),
                        format_func=lambda x: f"{x}ï¼ˆä½™ {pool_df.set_index('æ± ç¼–å·').at[x, 'å‰©ä½™ç©ºé—´']} åªï¼‰"
                    )
                else:
                    target_pool = None

                uploaded = st.file_uploader(
                    "ğŸ“¸ ä¸Šä¼ ç°åœºå›¾ç‰‡/è§†é¢‘ï¼ˆå¯å¤šé€‰ï¼‰",
                    type=["jpg", "jpeg", "png", "mp4", "mov"],
                    accept_multiple_files=True,
                    key=f"up_sort_egg_{batch_no}_{rnd}"
                )

                if st.form_submit_button("æäº¤åˆ†æ‹£") and avg_w >= 20 and target_pool and total > 0:
                    # âœ… ç»Ÿä¸€ç”¨ã€Œæˆè›™ã€è¿‡æ¸¡ç±»å‹ï¼Œä¸å†æŒ‘ SP_xxx
                    frog_details = {"æˆè›™": total}
                    ok, msg = record_sorting(
                        batch_no, rnd, datetime.combine(dt, tm),
                        total, frog_details, operator.strip(),
                        target_pool, media_files=uploaded
                    )
                    if ok:
                        st.success(f"âœ… å·²åˆ†æ‹£ {total} åªåˆ° {target_pool}")
                        get_sorted_frog_total_by_source.clear()
                        st.rerun()
                    else:
                        st.error(msg)

        st.markdown("---")
        st.subheader("3. æˆè›™å†åˆ†ç±»ï¼ˆè‡ªå…»åµï¼‰")
        skin = st.radio("é€‰æ‹©çš®å‹", ["ç»†çš®", "ç²—çš®"], key="reclass_egg_skin", horizontal=True)

        # è·å–è¯¥æ¥æº+çš®å‹ä¸‹çš„æ‰€æœ‰å…·ä½“æˆè›™æ± 
        pool_df = get_frog_pools(pool_type='è‡ªå…»åµ', skin_type=skin)
        pool_df = pool_df[~pool_df['æ± ç¼–å·'].str.contains('å•†å“è›™æ± ')] 
        if pool_df.empty:
            st.warning("æš‚æ— å¯ç”¨æˆè›™æ± ")
        else:
            pool_options = pool_df['æ± ç¼–å·'].tolist()
            selected_pool = st.selectbox("é€‰æ‹©è¦å†åˆ†ç±»çš„æˆè›™æ± ", pool_options, key=f"reclass_pool_egg_{skin}")
            _show_reclass_ui(selected_pool, operator)

        st.markdown("---")
        st.subheader("4. é”€å”®ï¼ˆè‡ªå…»åµï¼‰")
        skin = st.radio("é€‰æ‹©çš®å‹", ["ç»†çš®", "ç²—çš®"], key="sale_egg_skin", horizontal=True)

        # è·å–æ‰€æœ‰å¯é”€å”®æ± ï¼ˆå•†å“è›™æ±  + å¹´é™æ± ï¼‰
        sale_pools = get_frog_pools(purpose="sale")
        if sale_pools.empty:
            st.warning("æš‚æ— å¯å”®æ± ï¼Œè¯·å…ˆåˆå§‹åŒ–æ± åŒºä¿¡æ¯")
        else:
            # ä¸ºå¹´é™æ± è¡¥å……æ¥æºå’Œçš®å‹
            def enrich_pool_info(row):
                pool_code = row['æ± ç¼–å·']
                if row['æ¥æº/å¹´é™'] in ['ä¸‰å¹´è›™', 'å››å¹´è›™', 'äº”å¹´è›™', 'ç§è›™', 'è¯•éªŒè›™']:
                    source, skin_type = get_pool_source_and_skin(pool_code)
                    return pd.Series([source, skin_type])
                else:
                    # å•†å“è›™æ± ï¼šç›´æ¥ç”¨ pool_type å’Œ skin_type
                    return pd.Series([row['æ¥æº/å¹´é™'], row['çš®å‹']])
            
            sale_pools[['æ¨æ–­_æ¥æº', 'æ¨æ–­_çš®å‹']] = sale_pools.apply(enrich_pool_info, axis=1)
            
            # ç­›é€‰ï¼šæ¥æº=è‡ªå…»åµ ä¸” çš®å‹=ç”¨æˆ·é€‰æ‹©
            filtered_pools = sale_pools[
                (sale_pools['æ¨æ–­_æ¥æº'] == 'è‡ªå…»åµ') &
                (sale_pools['æ¨æ–­_çš®å‹'] == skin)
            ]
            
            if filtered_pools.empty:
                st.warning(f"æš‚æ—  è‡ªå…»åµ-{skin} çš„å¯é”€å”®æ± ï¼ˆåŒ…æ‹¬å•†å“è›™æ± å’Œå¹´é™æ± ï¼‰")
            else:
                selected_pool = st.selectbox(
                    "é€‰æ‹©é”€å”®æ± åŒº",
                    filtered_pools['æ± ç¼–å·'].tolist(),
                    format_func=lambda x: f"{x}ï¼ˆå½“å‰æ•°é‡ï¼š{int(filtered_pools.set_index('æ± ç¼–å·').loc[x, 'å½“å‰æ•°é‡'])}åªï¼‰"
                )
                _show_sale_ui(selected_pool, operator)

    # ========== 2. å¤–è´­èŒèšª ==========
    with tab_tadpole:
        st.subheader("1. æ‰¹æ¬¡æŠ•å…¥ï¼ˆå¤–è´­èŒèšªï¼‰")
        free = fetch_incubation_pools("ç©ºé—²")
        if not free:
            st.warning("æ²¡æœ‰å¯ç”¨çš„ç©ºé—²å­µåŒ–æ± ")
        else:
            with st.form("batch_tad"):
                col1, col2 = st.columns(2)
                with col1:
                    opts = [f"{p[0]} ({p[1]})" for p in free]
                    sel = st.selectbox("é€‰æ‹©å­µåŒ–æ± ", opts)
                    pool_no = sel.split()[0]
                    unit = st.radio("å•ä½", ["åª", "æ–¤"])
                    qty = st.number_input("æ•°é‡", min_value=0.01)
                with col2:
                    dt = st.date_input("æ—¥æœŸ", datetime.now(), key="tad_d")
                    tm = st.time_input("æ—¶é—´", datetime.now().time(), key="tad_t")
                    input_time = datetime.combine(dt, tm)
                uploaded = st.file_uploader(
                    "ğŸ“¸ ä¸Šä¼ ç°åœºå›¾ç‰‡/è§†é¢‘ï¼ˆå¯å¤šé€‰ï¼‰",
                    type=["jpg", "jpeg", "png", "mp4", "mov"],
                    accept_multiple_files=True,
                    key=f"up_tad_batch_{pool_no}"
                )
                if st.form_submit_button("æäº¤"):
                    ok, msg = create_batch(pool_no, "å¤–è´­èŒèšª", qty, unit, input_time,
                                           operator.strip(), media_files=uploaded)
                    if ok:
                        st.success(msg)
                        st.rerun()
                    else:
                        st.error(msg)

        st.markdown("---")
        st.subheader("2. åˆ†æ‰¹åˆ†æ‹£ï¼ˆå¤–è´­èŒèšª â†’ æˆè›™æ± ï¼‰")

        sorted_total = get_sorted_frog_total_by_source("å¤–è´­èŒèšª")
        st.info(f"ğŸ“Š å¤–è´­èŒèšªæµç¨‹å·²åˆ†æ‹£åˆ°æˆè›™æ± ç´¯è®¡ï¼š**{sorted_total} åª**")

        active = [b for b in fetch_active_batches() if b[2] == "å¤–è´­èŒèšª"]
        if not active:
            st.info("æš‚æ— å¤–è´­èŒèšªæ´»è·ƒæ‰¹æ¬¡")
        else:
            batch_opts = [f"{b[0]} ({b[1]})" for b in active]
            sel = st.selectbox("é€‰æ‹©æ‰¹æ¬¡", batch_opts)
            batch_no = sel.split()[0]

            # æŠŠ radio æ”¾åœ¨è¡¨å•å¤–ï¼Œåˆ‡æ¢ç«‹å³åˆ·æ–°æ± æ•°æ®
            skin = st.radio("çš®å‹", ["ç»†çš®", "ç²—çš®"], horizontal=True, key="tad_skin_radio")

            with st.form("sort_tad"):
                col1, col2 = st.columns(2)
                with col1:
                    with DatabaseConnection() as conn:
                        with conn.cursor() as cur:
                            cur.execute("SELECT COALESCE(MAX(round_no),0)+1 FROM t_batch_sorting_record WHERE batch_no=%s",(batch_no,))
                            rnd = cur.fetchone()[0]
                    total = st.number_input("åˆ†æ‹£æ•°é‡ï¼ˆåªï¼‰", min_value=1)
                    avg_w = st.number_input("å¹³å‡é‡é‡ï¼ˆå…‹ï¼‰", min_value=0.1, value=25.0)
                with col2:
                    dt = st.date_input("åˆ†æ‹£æ—¥æœŸ", datetime.now(), key="sort_tad_d")
                    tm = st.time_input("åˆ†æ‹£æ—¶é—´", datetime.now().time(), key="sort_tad_t")

                # ===== æˆè›™æ± é€‰æ‹© =====================================
                pool_df = get_frog_pools(pool_type='å¤–è´­èŒèšª', skin_type=skin)
                pool_df = pool_df[~pool_df['æ± ç¼–å·'].str.contains('å•†å“è›™æ± ')]
                if pool_df.empty:
                    st.error('æš‚æ— å¯¹åº”æˆè›™æ± ï¼Œè¯·å…ˆè”ç³»ç®¡ç†å‘˜å»ºæ± ')
                    st.stop()

                st.write("ğŸ“ æˆè›™æ± å®¹é‡æ¦‚è§ˆ")
                st.dataframe(pool_df, use_container_width=True)

                full_pools = pool_df[pool_df['å‰©ä½™ç©ºé—´'] <= 0]['æ± ç¼–å·'].tolist()
                if full_pools:
                    st.error(f"æ± å­ {full_pools} å·²æ»¡ 500 åªï¼Œè¯·å…ˆå¢åŠ æ–°æ± å†åˆ†æ‹£ï¼")
                    st.stop()

                target_pool = st.selectbox(
                    "è¯·é€‰æ‹©ç›®æ ‡æˆè›™æ± ",
                    pool_df['æ± ç¼–å·'].tolist(),
                    format_func=lambda x: f"{x}ï¼ˆä½™ {pool_df.set_index('æ± ç¼–å·').at[x, 'å‰©ä½™ç©ºé—´']} åªï¼‰"
                )
                # ======================================================

                uploaded = st.file_uploader(
                    "ğŸ“¸ ä¸Šä¼ ç°åœºå›¾ç‰‡/è§†é¢‘ï¼ˆå¯å¤šé€‰ï¼‰",
                    type=["jpg", "jpeg", "png", "mp4", "mov"],
                    accept_multiple_files=True,
                    key=f"up_sort_tad_{batch_no}_{rnd}"
                )
                if st.form_submit_button("æäº¤åˆ†æ‹£") and avg_w >= 20:
                    frog_types = fetch_frog_types()
                    use_type = next((c for c, _ in frog_types if c.startswith("SP_") and c != "SP"), "SP_å•†å“è›™")
                    ok, msg = record_sorting(batch_no, rnd, datetime.combine(dt, tm),
                                             total, {use_type: total}, operator.strip(),
                                             target_pool, media_files=uploaded)
                    if ok:
                        st.success(f"âœ… åˆ†æ‹£åˆ° {target_pool}")
                        st.rerun()
                    else:
                        st.error(msg)

        st.markdown("---")
        st.subheader("3. æˆè›™å†åˆ†ç±»ï¼ˆå¤–è´­èŒèšªï¼‰")
        skin = st.radio("é€‰æ‹©çš®å‹", ["ç»†çš®", "ç²—çš®"], key="reclass_tad_skin", horizontal=True)
        pool_df = get_frog_pools(pool_type='å¤–è´­èŒèšª', skin_type=skin)
        pool_df = pool_df[~pool_df['æ± ç¼–å·'].str.contains('å•†å“è›™æ± ')]
        if pool_df.empty:
            st.warning("æš‚æ— å¯ç”¨çš„å¤–è´­èŒèšªæˆè›™æ± ")
        else:
            selected_pool = st.selectbox("é€‰æ‹©è¦å†åˆ†ç±»çš„æˆè›™æ± ", pool_df['æ± ç¼–å·'].tolist(), key=f"reclass_pool_tad_{skin}")
            _show_reclass_ui(selected_pool, operator)

        st.markdown("---")
        st.subheader("4. é”€å”®ï¼ˆå¤–è´­èŒèšªï¼‰")
        skin = st.radio("é€‰æ‹©çš®å‹", ["ç»†çš®", "ç²—çš®"], key="sale_tad_skin", horizontal=True)

        # è·å–æ‰€æœ‰å¯é”€å”®æ± ï¼ˆå•†å“è›™æ±  + å¹´é™æ± ï¼‰
        sale_pools = get_frog_pools(purpose="sale")
        if sale_pools.empty:
            st.warning("æš‚æ— å¯å”®æ± ï¼Œè¯·å…ˆåˆå§‹åŒ–æ± åŒºä¿¡æ¯")
        else:
            def enrich_pool_info(row):
                pool_code = row['æ± ç¼–å·']
                if row['æ¥æº/å¹´é™'] in ['ä¸‰å¹´è›™', 'å››å¹´è›™', 'äº”å¹´è›™', 'ç§è›™', 'è¯•éªŒè›™']:
                    source, skin_type = get_pool_source_and_skin(pool_code)
                    return pd.Series([source, skin_type])
                else:
                    return pd.Series([row['æ¥æº/å¹´é™'], row['çš®å‹']])
            
            sale_pools[['æ¨æ–­_æ¥æº', 'æ¨æ–­_çš®å‹']] = sale_pools.apply(enrich_pool_info, axis=1)
            filtered_pools = sale_pools[
                (sale_pools['æ¨æ–­_æ¥æº'] == 'å¤–è´­èŒèšª') &
                (sale_pools['æ¨æ–­_çš®å‹'] == skin)
            ]
            
            if filtered_pools.empty:
                st.warning(f"æš‚æ—  å¤–è´­èŒèšª-{skin} çš„å¯é”€å”®æ± ï¼ˆåŒ…æ‹¬å•†å“è›™æ± å’Œå¹´é™æ± ï¼‰")
            else:
                selected_pool = st.selectbox(
                    "é€‰æ‹©é”€å”®æ± åŒº",
                    filtered_pools['æ± ç¼–å·'].tolist(),
                    format_func=lambda x: f"{x}ï¼ˆå½“å‰æ•°é‡ï¼š{int(filtered_pools.set_index('æ± ç¼–å·').loc[x, 'å½“å‰æ•°é‡'])}åªï¼‰"
                )
                _show_sale_ui(selected_pool, operator)

    # ========== 3. å¤–è´­å¹¼è›™ ==========
    with tab_young:
        st.markdown("---")
        st.subheader("1. å¤–è´­å¹¼è›™å…¥åº“ï¼ˆç›´æ¥è¿›æˆè›™æ± ï¼‰")

        sorted_total = get_sorted_frog_total_by_source("å¤–è´­å¹¼è›™")
        st.info(f"ğŸ“Š å¤–è´­å¹¼è›™æµç¨‹å·²åˆ†æ‹£åˆ°æˆè›™æ± ç´¯è®¡ï¼š**{sorted_total} åª**")

        frog_types = fetch_frog_types()
        valid_sp = [c for c, _ in frog_types if c.startswith("SP_") and c != "SP"]
        if not valid_sp:
            st.warning("æœªå®šä¹‰å•†å“è›™å­ç±»å‹")
        else:
            # æŠŠ radio æ”¾åœ¨è¡¨å•å¤–ï¼Œåˆ‡æ¢ç«‹å³åˆ·æ–°æ± æ•°æ®
            skin = st.radio("çš®å‹", ["ç»†çš®", "ç²—çš®"], horizontal=True, key="young_skin_radio")

            with st.form("direct_young"):
                col1, col2 = st.columns(2)
                with col1:
                    opts = [f"{c} - {d}" for c, d in frog_types if c in valid_sp]
                    sel = st.selectbox("å¹¼è›™ç±»å‹", opts)
                    frog_type = sel.split(" - ")[0]
                    qty = st.number_input("æ•°é‡", min_value=1)
                with col2:
                    dt = st.date_input("æ—¥æœŸ", datetime.now(), key="young_d")
                    tm = st.time_input("æ—¶é—´", datetime.now().time(), key="young_t")
                    input_time = datetime.combine(dt, tm)

                # ===== æˆè›™æ± é€‰æ‹© =====================================
                pool_df = get_frog_pools(pool_type='å¤–è´­å¹¼è›™', skin_type=skin)
                pool_df = pool_df[~pool_df['æ± ç¼–å·'].str.contains('å•†å“è›™æ± ')]
                if pool_df.empty:
                    st.error('æš‚æ— å¯¹åº”æˆè›™æ± ï¼Œè¯·å…ˆè”ç³»ç®¡ç†å‘˜å»ºæ± ')
                    st.stop()

                st.write("ğŸ“ æˆè›™æ± å®¹é‡æ¦‚è§ˆ")
                st.dataframe(pool_df, use_container_width=True)

                full_pools = pool_df[pool_df['å‰©ä½™ç©ºé—´'] <= 0]['æ± ç¼–å·'].tolist()
                if full_pools:
                    st.error(f"æ± å­ {full_pools} å·²æ»¡ 500 åªï¼Œè¯·å…ˆå¢åŠ æ–°æ± å†å…¥åº“ï¼")
                    st.stop()

                target_pool = st.selectbox(
                    "è¯·é€‰æ‹©ç›®æ ‡æˆè›™æ± ",
                    pool_df['æ± ç¼–å·'].tolist(),
                    format_func=lambda x: f"{x}ï¼ˆä½™ {pool_df.set_index('æ± ç¼–å·').at[x, 'å‰©ä½™ç©ºé—´']} åªï¼‰"
                )
                # ======================================================

                uploaded = st.file_uploader(
                    "ğŸ“¸ ä¸Šä¼ ç°åœºå›¾ç‰‡/è§†é¢‘ï¼ˆå¯å¤šé€‰ï¼‰",
                    type=["jpg", "jpeg", "png", "mp4", "mov"],
                    accept_multiple_files=True,
                    key=f"up_young_direct_{frog_type}"
                )
                if st.form_submit_button("æäº¤å…¥åº“"):
                    ok, msg = record_direct_frog_input(frog_type, qty, input_time,
                                                       operator.strip(), target_pool,
                                                       "å¤–è´­å¹¼è›™å…¥åº“", media_files=uploaded)
                    if ok:
                        st.success(msg)
                        st.rerun()
                    else:
                        st.error(msg)

        st.markdown("---")
        st.subheader("2. æˆè›™å†åˆ†ç±»ï¼ˆå¤–è´­å¹¼è›™ï¼‰")
        skin = st.radio("é€‰æ‹©çš®å‹", ["ç»†çš®", "ç²—çš®"], key="reclass_young_skin", horizontal=True)
        pool_df = get_frog_pools(pool_type='å¤–è´­å¹¼è›™', skin_type=skin)
        pool_df = pool_df[~pool_df['æ± ç¼–å·'].str.contains('å•†å“è›™æ± ')]
        if pool_df.empty:
            st.warning("æš‚æ— å¯ç”¨çš„å¤–è´­å¹¼è›™æˆè›™æ± ")
        else:
            selected_pool = st.selectbox("é€‰æ‹©è¦å†åˆ†ç±»çš„æˆè›™æ± ", pool_df['æ± ç¼–å·'].tolist(), key=f"reclass_pool_young_{skin}")
            _show_reclass_ui(selected_pool, operator)

        st.markdown("---")
        st.subheader("3. é”€å”®ï¼ˆå¤–è´­å¹¼è›™ï¼‰")
        skin = st.radio("é€‰æ‹©çš®å‹", ["ç»†çš®", "ç²—çš®"], key="sale_young_skin", horizontal=True)

        # è·å–æ‰€æœ‰å¯é”€å”®æ± ï¼ˆå•†å“è›™æ±  + å¹´é™æ± ï¼‰
        sale_pools = get_frog_pools(purpose="sale")
        if sale_pools.empty:
            st.warning("æš‚æ— å¯å”®æ± ï¼Œè¯·å…ˆåˆå§‹åŒ–æ± åŒºä¿¡æ¯")
        else:
            def enrich_pool_info(row):
                pool_code = row['æ± ç¼–å·']
                if row['æ¥æº/å¹´é™'] in ['ä¸‰å¹´è›™', 'å››å¹´è›™', 'äº”å¹´è›™', 'ç§è›™', 'è¯•éªŒè›™']:
                    source, skin_type = get_pool_source_and_skin(pool_code)
                    return pd.Series([source, skin_type])
                else:
                    return pd.Series([row['æ¥æº/å¹´é™'], row['çš®å‹']])
            
            sale_pools[['æ¨æ–­_æ¥æº', 'æ¨æ–­_çš®å‹']] = sale_pools.apply(enrich_pool_info, axis=1)
            filtered_pools = sale_pools[
                (sale_pools['æ¨æ–­_æ¥æº'] == 'å¤–è´­å¹¼è›™') &
                (sale_pools['æ¨æ–­_çš®å‹'] == skin)
            ]
            
            if filtered_pools.empty:
                st.warning(f"æš‚æ—  å¤–è´­å¹¼è›™-{skin} çš„å¯é”€å”®æ± ï¼ˆåŒ…æ‹¬å•†å“è›™æ± å’Œå¹´é™æ± ï¼‰")
            else:
                selected_pool = st.selectbox(
                    "é€‰æ‹©é”€å”®æ± åŒº",
                    filtered_pools['æ± ç¼–å·'].tolist(),
                    format_func=lambda x: f"{x}ï¼ˆå½“å‰æ•°é‡ï¼š{int(filtered_pools.set_index('æ± ç¼–å·').loc[x, 'å½“å‰æ•°é‡'])}åªï¼‰"
                )
                _show_sale_ui(selected_pool, operator)

    # ========== 4. å¤–è´­æˆè›™ ==========
    with tab_adult:
        st.subheader("1. å¤–è´­æˆè›™å…¥åº“ï¼ˆç›´æ¥è¿›å•†å“è›™æ± ï¼‰")
        frog_types = fetch_frog_types()
        valid_sp = [c for c, _ in frog_types if c.startswith("SP_") and c != "SP"]
        if not valid_sp:
            st.warning("æœªå®šä¹‰å•†å“è›™å­ç±»å‹")
        else:
            with st.form("direct_adult"):
                col1, col2 = st.columns(2)
                with col1:
                    opts = [f"{c} - {d}" for c, d in frog_types if c in valid_sp]
                    sel = st.selectbox("æˆè›™ç±»å‹", opts)
                    frog_type = sel.split(" - ")[0]
                    target_pool = "å¤–è´­æˆè›™-å•†å“è›™æ± "
                    qty = st.number_input("æ•°é‡", min_value=1)
                with col2:
                    dt = st.date_input("æ—¥æœŸ", datetime.now(), key="adult_d")
                    tm = st.time_input("æ—¶é—´", datetime.now().time(), key="adult_t")
                    input_time = datetime.combine(dt, tm)
                uploaded = st.file_uploader(
                    "ğŸ“¸ ä¸Šä¼ ç°åœºå›¾ç‰‡/è§†é¢‘ï¼ˆå¯å¤šé€‰ï¼‰",
                    type=["jpg", "jpeg", "png", "mp4", "mov"],
                    accept_multiple_files=True,
                    key=f"up_adult_direct_{frog_type}"
                )
                if st.form_submit_button("æäº¤å…¥åº“"):
                    ok, msg = record_direct_frog_input(frog_type, qty, input_time,
                                                       operator.strip(), target_pool,
                                                       "å¤–è´­æˆè›™å…¥åº“", media_files=uploaded)
                    if ok:
                        st.success(msg)
                        st.rerun()
                    else:
                        st.error(msg)

        st.markdown("---")
        st.subheader("2. é”€å”®ï¼ˆå¤–è´­æˆè›™ï¼‰")
        skin = st.radio("é€‰æ‹©çš®å‹", ["ç»†çš®", "ç²—çš®"], key="sale_adult_skin", horizontal=True)

        # è·å–æ‰€æœ‰å¯é”€å”®æ± ï¼ˆå•†å“è›™æ±  + å¹´é™æ± ï¼‰
        sale_pools = get_frog_pools(purpose="sale")
        if sale_pools.empty:
            st.warning("æš‚æ— å¯å”®æ± ï¼Œè¯·å…ˆåˆå§‹åŒ–æ± åŒºä¿¡æ¯")
        else:
            def enrich_pool_info(row):
                pool_code = row['æ± ç¼–å·']
                if row['æ¥æº/å¹´é™'] in ['ä¸‰å¹´è›™', 'å››å¹´è›™', 'äº”å¹´è›™', 'ç§è›™', 'è¯•éªŒè›™']:
                    source, skin_type = get_pool_source_and_skin(pool_code)
                    return pd.Series([source, skin_type])
                else:
                    return pd.Series([row['æ¥æº/å¹´é™'], row['çš®å‹']])
            
            sale_pools[['æ¨æ–­_æ¥æº', 'æ¨æ–­_çš®å‹']] = sale_pools.apply(enrich_pool_info, axis=1)
            filtered_pools = sale_pools[
                (sale_pools['æ¨æ–­_æ¥æº'] == 'å¤–è´­æˆè›™') &
                (sale_pools['æ¨æ–­_çš®å‹'] == skin)
            ]
            
            if filtered_pools.empty:
                st.warning(f"æš‚æ—  å¤–è´­æˆè›™-{skin} çš„å¯é”€å”®æ± ï¼ˆåŒ…æ‹¬å•†å“è›™æ± å’Œå¹´é™æ± ï¼‰")
            else:
                selected_pool = st.selectbox(
                    "é€‰æ‹©é”€å”®æ± åŒº",
                    filtered_pools['æ± ç¼–å·'].tolist(),
                    format_func=lambda x: f"{x}ï¼ˆå½“å‰æ•°é‡ï¼š{int(filtered_pools.set_index('æ± ç¼–å·').loc[x, 'å½“å‰æ•°é‡'])}åªï¼‰"
                )
                _show_sale_ui(selected_pool, operator)

    # ========== é€šç”¨æŠ˜å åŒº ==========
    st.markdown("---")
    st.subheader("é€šç”¨æ“ä½œï¼ˆæ‰€æœ‰æ¥æºå…±äº«ï¼‰")

    # ---- æ‰¹æ¬¡å®Œæˆ ----
    with st.expander("æ‰¹æ¬¡å®Œæˆ"):
        active = fetch_active_batches()
        if active:
            with st.form("complete_batch"):
                opts = [f"{b[0]} ({b[2]})" for b in active]
                sel = st.selectbox("é€‰æ‹©æ‰¹æ¬¡", opts)
                batch_no = sel.split()[0]
                dt = st.date_input("å®Œæˆæ—¥æœŸ", datetime.now(), key="comp_d")
                tm = st.time_input("å®Œæˆæ—¶é—´", datetime.now().time(), key="comp_t")
                uploaded = st.file_uploader(
                    "ğŸ“¸ ä¸Šä¼ å®Œæˆå‡­è¯ï¼ˆå¯å¤šé€‰ï¼‰",
                    type=["jpg", "jpeg", "png"],
                    accept_multiple_files=True,
                    key=f"up_complete_{batch_no}"
                )
                if st.form_submit_button("å®Œæˆæ‰¹æ¬¡"):
                    ok, msg = complete_batch(batch_no, datetime.combine(dt, tm),
                                             operator.strip(), media_files=uploaded)
                    if ok:
                        st.success(msg)
                        st.rerun()
                    else:
                        st.error(msg)
# ----------------------------- è¾…åŠ© UI å‡½æ•°ï¼ˆå·²æ”¯æŒä¸Šä¼ ï¼‰ ----------------------------- #
def _show_reclass_ui(from_pool_area: str, operator: str):
    from datetime import datetime

    st.info(f"ğŸ“ æ¥æºæ± åŒºï¼š{from_pool_area}")

    # 1. å½“å‰åº“å­˜ï¼ˆç»Ÿä¸€ç”¨â€œæˆè›™â€ç±»å‹ï¼‰
    with DatabaseConnection() as conn:
        if conn:
            with conn.cursor() as cur:
                cur.execute(
                    """SELECT COALESCE(SUM(quantity),0)
                       FROM t_frog_inventory
                       WHERE pool_area = %s AND frog_type_code = 'æˆè›™'""",
                    (from_pool_area,),
                )
                current_qty = int(cur.fetchone()[0])
    if current_qty <= 0:
        st.warning("æˆè›™æ± æ— å•†å“è›™åº“å­˜ï¼Œæ— æ³•æ‹†åˆ†")
        return

    st.success(f"å½“å‰â€œæˆè›™â€åº“å­˜ï¼š{current_qty} åª")

    # 2. åˆ—å‡ºæ‰€æœ‰å¹´é™ç»†åˆ†æ± 
    year_df = get_frog_pools(purpose="year")          # â† å…³é”®è°ƒç”¨
    if year_df.empty:
        st.error("æœªæ‰¾åˆ°ä»»ä½•å¹´é™ç»†åˆ†æ± ï¼Œè¯·å…ˆåˆå§‹åŒ–æ•°æ®åº“")
        return

    st.write("ğŸ“Š ç›®æ ‡æ± å®¹é‡æ¦‚è§ˆ")
    st.dataframe(year_df, use_container_width=True)

    # 3. åŠ¨æ€è¾“å…¥æ‹†åˆ†æ•°é‡
    with st.form(key=f"reclass_{from_pool_area}"):
        qty_map = {}
        cols = st.columns(3)
        for idx, row in year_df.iterrows():
            col = cols[idx % 3]
            max_val = int(row['å‰©ä½™ç©ºé—´'])
            if max_val <= 0:
                col.warning(f"{row['æ± ç¼–å·']} å·²æ»¡")
                continue
            qty = col.number_input(
                f"æ‹†åˆ° {row['æ± ç¼–å·']}",
                min_value=0,
                max_value=max_val,
                step=1,
                key=f"qty_{row['æ± ç¼–å·']}"
            )
            if qty:
                qty_map[row['æ± ç¼–å·']] = qty

        dt = st.date_input("æ—¥æœŸ", datetime.now())
        tm = st.time_input("æ—¶é—´", datetime.now().time())
        reclass_time = datetime.combine(dt, tm)

        uploaded = st.file_uploader(
            "ğŸ“¸ ä¸Šä¼ ç°åœºå›¾ç‰‡/è§†é¢‘ï¼ˆå¯å¤šé€‰ï¼‰",
            type=["jpg", "jpeg", "png", "mp4", "mov"],
            accept_multiple_files=True,
            key=f"media_reclass_{from_pool_area}"
        )

        submitted = st.form_submit_button("æäº¤æ‹†åˆ†")
        if submitted:
            total_out = sum(qty_map.values())
            if total_out == 0:
                st.error("è‡³å°‘æ‹† 1 åª")
            elif total_out > current_qty:
                st.error(f"æ‹†åˆ†æ€»é‡ {total_out} è¶…è¿‡åº“å­˜ {current_qty}")
            else:
                # æ„é€  to_detailsï¼š{frog_type: qty}
                # è¿™é‡Œç»Ÿä¸€ç”¨â€œSP_ä¸‰å¹´è›™â€è¿™ç±»ç¼–ç ï¼Œåç»­å¯å†ç»†åŒ–
                type_map = {
                    "ä¸‰å¹´è›™æ± -001": "SP_ä¸‰å¹´è›™",
                    "å››å¹´è›™æ± -001": "SP_å››å¹´è›™",
                    "äº”å¹´è›™æ± -001": "SP_äº”å¹´è›™",
                    "ç§è›™æ± -001":   "ZB_æ¯ç§",
                    "è¯•éªŒè›™æ± -001": "SY_å¯¹ç…§ç»„",
                }
                to_details = {type_map[pool]: q for pool, q in qty_map.items() if q > 0}

                ok, msg = record_frog_reclassification_to_target(
                    from_pool_area, to_details, reclass_time, operator.strip(), media_files=uploaded
                )
                if ok:
                    st.success(msg)
                    st.rerun()
                else:
                    st.error(msg)
def record_frog_reclassification_to_target(
    from_pool_area: str,
    to_details: dict,  # {SP_ä¸‰å¹´è›™: 2, ZB_æ¯ç§: 1, ...}
    reclass_time: datetime,
    operator: str,
    media_files=None,
):
    """
    å†åˆ†ç±»ï¼šä»æˆè›™æ± æ‰£ã€Œæˆè›™ã€ç±»å‹ï¼ŒæŒ‰ to_details æ‹†æ’åˆ°å¹´é™/ç§/è¯•éªŒæ± 
    æ¯ä¸ªç›®æ ‡æ± å•ç‹¬è®°å½•ä¸€æ¡è¡Œä¸ºæ—¥å¿—ï¼Œä¾¿äºé”€å”®æ¨¡å—æº¯æº
    """
    try:
        with DatabaseConnection() as conn:
            if not conn:
                return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"
            with conn.cursor() as cur:
                cur.execute("BEGIN")
                total_need = sum(to_details.values())
                if total_need <= 0:
                    conn.rollback()
                    return False, "æ‹†åˆ†æ•°é‡ä¸º 0"
                # 1. æ£€æŸ¥æˆè›™æ± ã€Œæˆè›™ã€åº“å­˜
                cur.execute(
                    """SELECT quantity
                       FROM t_frog_inventory
                       WHERE pool_area = %s AND frog_type_code = 'æˆè›™'""",
                    (from_pool_area,),
                )
                row = cur.fetchone()
                if not row or row[0] < total_need:
                    return False, f"{from_pool_area} ä¸­ æˆè›™ åº“å­˜ä¸è¶³ï¼ˆéœ€ {total_need}ï¼Œå®æœ‰ {row[0] if row else 0}ï¼‰"
                # 2. æ‰£å‡æˆè›™æ± ã€Œæˆè›™ã€
                cur.execute(
                    """UPDATE t_frog_inventory
                       SET quantity = quantity - %s, last_update_time = CURRENT_TIMESTAMP
                       WHERE pool_area = %s AND frog_type_code = 'æˆè›™'""",
                    (total_need, from_pool_area),
                )
                # 3. ç›®æ ‡æ± æ˜ å°„
                target_pool_map = {
                    "SP_ä¸‰å¹´è›™":  "ä¸‰å¹´è›™æ± -001",
                    "SP_å››å¹´è›™":  "å››å¹´è›™æ± -001",
                    "SP_äº”å¹´è›™":  "äº”å¹´è›™æ± -001",
                    "ZB_æ¯ç§":   "ç§è›™æ± -001",
                    "ZB_å…¬ç§":   "ç§è›™æ± -001",
                    "SY_å¯¹ç…§ç»„": "è¯•éªŒè›™æ± -001",
                }
                # 4. ä¸ºæ¯ä¸ªç›®æ ‡æ± æ’å…¥åº“å­˜ + è¡Œä¸ºè®°å½•
                for frog_type, qty in to_details.items():
                    if qty <= 0:
                        continue
                    target_pool = target_pool_map.get(frog_type)
                    if not target_pool:
                        continue
                    # æ’å…¥/æ›´æ–°åº“å­˜
                    cur.execute(
                        """INSERT INTO t_frog_inventory (frog_type_code, quantity, pool_area)
                           VALUES (%s, %s, %s)
                           ON CONFLICT (frog_type_code, pool_area)
                           DO UPDATE SET
                               quantity = t_frog_inventory.quantity + EXCLUDED.quantity,
                               last_update_time = CURRENT_TIMESTAMP""",
                        (frog_type, qty, target_pool),
                    )
                    # ğŸ‘‡ å…³é”®ï¼šä¸ºæ¯ä¸ªç›®æ ‡æ± å•ç‹¬è®°å½•ä¸€æ¡è¡Œä¸ºæ—¥å¿—
                    record_id = str(uuid.uuid4())
                    cur.execute(
                        """INSERT INTO t_business_behavior_record
                           (record_id, behavior_type, operation_value, operation_time, operator, remarks)
                           VALUES (%s, 'æˆè›™å†åˆ†ç±»', %s, %s, %s, %s)""",
                        (record_id, qty, reclass_time, operator.strip(), 
                         f"ä» {from_pool_area} æ‹†åˆ† {qty} åªåˆ° {target_pool}"),
                    )
                conn.commit()
                if media_files:
                    save_uploaded_media(media_files, str(uuid.uuid4()), "reclass", pool_no=from_pool_area)
                return True, f"âœ… å·²ä» {from_pool_area} æ‹†åˆ† {total_need} åªåˆ°å¯¹åº”æ± "
    except Exception as e:
        return False, f"æ‹†åˆ†å¤±è´¥: {e}"
def _show_sale_ui(pool_area: str, operator: str):
    """
    é”€å”®ç»Ÿä¸€å…¥å£ï¼šæ”¯æŒæ‰€æœ‰å¯å”®æ± ï¼ˆæ¥æºå•†å“è›™æ±  + ä¸‰å¹´/å››å¹´/äº”å¹´/ç§/è¯•éªŒæ± ï¼‰
    åŠŸèƒ½ï¼š
    1. é”€å”®ç»Ÿè®¡ï¼ˆæŒ‰å¤©/æœˆ/æ¥æº/ç±»å‹ï¼‰
    2. æ–°å¢é”€å”®è¡¨å•ï¼ˆå¸¦å®¢æˆ·ã€å•ä»·ã€å¤‡æ³¨ã€å¤šåª’ä½“ï¼‰
    3. å¯¼å‡ºè¯¦ç»†é”€å”®è®°å½• CSV
    """
    from datetime import datetime, timedelta
    import plotly.express as px

    st.subheader(f"ğŸ“¦ é”€å”®æ“ä½œ - {pool_area}")

    # â”Œ------------------------- é”€å”®ç»Ÿè®¡åŒºåŸŸ -------------------------â”
    st.markdown("---")
    st.subheader("ğŸ“Š é”€å”®ç»Ÿè®¡")

    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        stat_start = st.date_input("å¼€å§‹æ—¥æœŸ",
                                   value=datetime.now() - timedelta(days=30),
                                   key=f"stat_start_{pool_area}")
    with col2:
        stat_end = st.date_input("ç»“æŸæ—¥æœŸ",
                                 value=datetime.now(),
                                 key=f"stat_end_{pool_area}")
    with col3:
        group_by = st.selectbox("åˆ†ç»„æ–¹å¼",
                                ["æŒ‰å¤©", "æŒ‰æœˆ", "æŒ‰æ¥æºæ± åŒº", "æŒ‰è›™ç±»å‹"],
                                key=f"group_by_{pool_area}")

    # åˆ·æ–°æŒ‰é’®
    if st.button("ğŸ”„ åˆ·æ–°é”€å”®ç»Ÿè®¡", key=f"refresh_stats_{pool_area}"):
        get_sales_statistics.clear()

    # æŸ¥è¯¢é”€å”®æ•°æ®
    sales_df = get_sales_statistics(
        start_date=datetime.combine(stat_start, datetime.min.time()),
        end_date=datetime.combine(stat_end, datetime.max.time()),
        group_by={"æŒ‰å¤©": "day", "æŒ‰æœˆ": "month", "æŒ‰æ¥æºæ± åŒº": "source", "æŒ‰è›™ç±»å‹": "type"}[group_by]
    )

    if not sales_df.empty:
        # æ ¹æ®åˆ†ç»„å±•ç¤º
        if group_by == "æŒ‰å¤©":
            display_df = (sales_df
                          .groupby(["é”€å”®æ—¥æœŸ", "frog_type", "æ¥æºæ± åŒº"])["total_sold"]
                          .sum().reset_index()
                          .rename(columns={"é”€å”®æ—¥æœŸ": "æ—¥æœŸ", "frog_type": "è›™ç±»å‹",
                                           "total_sold": "é”€å”®æ•°é‡", "æ¥æºæ± åŒº": "æ¥æºæ± åŒº"}))
        elif group_by == "æŒ‰æœˆ":
            sales_df["æœˆä»½"] = sales_df["operation_time"].dt.to_period("M")
            display_df = (sales_df
                          .groupby(["æœˆä»½", "frog_type"])["total_sold"]
                          .sum().reset_index()
                          .rename(columns={"æœˆä»½": "æœˆä»½", "frog_type": "è›™ç±»å‹",
                                           "total_sold": "é”€å”®æ•°é‡"}))
        elif group_by == "æŒ‰æ¥æºæ± åŒº":
            display_df = (sales_df
                          .groupby(["æ¥æºæ± åŒº", "frog_type"])["total_sold"]
                          .sum().reset_index()
                          .rename(columns={"æ¥æºæ± åŒº": "æ¥æºæ± åŒº", "frog_type": "è›™ç±»å‹",
                                           "total_sold": "é”€å”®æ•°é‡"}))
        else:  # æŒ‰è›™ç±»å‹
            display_df = (sales_df
                          .groupby("frog_type")["total_sold"]
                          .sum().reset_index()
                          .rename(columns={"frog_type": "è›™ç±»å‹", "total_sold": "é”€å”®æ•°é‡"}))

        st.dataframe(display_df, use_container_width=True, hide_index=True)

        # å›¾è¡¨
        col_chart1, col_chart2 = st.columns(2)
        with col_chart1:
            if group_by in ("æŒ‰å¤©", "æŒ‰æœˆ"):
                time_df = (sales_df.groupby("period")["total_sold"]
                           .sum().reset_index())
                fig_trend = px.line(time_df, x="period", y="total_sold",
                                    title="é”€å”®è¶‹åŠ¿", markers=True)
                fig_trend.update_layout(xaxis_title="æ—¶é—´", yaxis_title="æ•°é‡ï¼ˆåªï¼‰")
                st.plotly_chart(fig_trend, use_container_width=True,
                                key=f"trend_{pool_area}_{group_by}")
        with col_chart2:
            if group_by == "æŒ‰è›™ç±»å‹":
                fig_pie = px.pie(display_df, values="é”€å”®æ•°é‡", names="è›™ç±»å‹",
                                 title="å„è›™ç±»å‹é”€å”®å æ¯”")
                st.plotly_chart(fig_pie, use_container_width=True,
                                key=f"pie_{pool_area}")
            else:
                source_df = (sales_df.groupby("æ¥æºæ± åŒº")["total_sold"]
                             .sum().reset_index())
                fig_bar = px.bar(source_df, x="æ¥æºæ± åŒº", y="total_sold",
                                 title="å„æ¥æºæ± åŒºé”€å”®æƒ…å†µ")
                st.plotly_chart(fig_bar, use_container_width=True,
                                key=f"bar_{pool_area}")

        # è¯¦ç»†è®°å½• & å¯¼å‡º
        with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†é”€å”®è®°å½•", expanded=False):
            detail_df = (sales_df[["operation_time", "frog_type", "total_sold",
                                   "æ¥æºæ± åŒº", "remarks"]]
                         .rename(columns={"operation_time": "é”€å”®æ—¶é—´",
                                          "frog_type": "è›™ç±»å‹",
                                          "total_sold": "é”€å”®æ•°é‡",
                                          "æ¥æºæ± åŒº": "æ¥æºæ± åŒº",
                                          "remarks": "å¤‡æ³¨"})
                         .assign(é”€å”®æ—¶é—´=lambda df: df["é”€å”®æ—¶é—´"].dt.strftime("%Y-%m-%d %H:%M")))
            st.dataframe(detail_df, use_container_width=True, hide_index=True)
            csv = detail_df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button("ğŸ“¥ å¯¼å‡ºCSV", data=csv,
                               file_name=f"é”€å”®è®°å½•_{pool_area}_{datetime.now():%Y%m%d}.csv",
                               mime="text/csv",
                               key=f"download_sales_{pool_area}")
    else:
        st.info("åœ¨é€‰å®šæ—¶é—´æ®µå†…æ— é”€å”®è®°å½•")

    # â”Œ------------------------- æ–°å¢é”€å”®åŒºåŸŸ -------------------------â”
    st.markdown("---")
    st.subheader("ğŸ’° æ–°å¢é”€å”®è®°å½•")

    # è·å–å½“å‰æ± çš„åº“å­˜
    inventory = get_pool_frog_inventory(pool_area)
    if not inventory:
        st.warning(f"æ± åŒº {pool_area} æš‚æ— åº“å­˜")
        return

    inventory_dict = {code: qty for code, desc, qty in inventory}

    # ä»…æ˜¾ç¤ºæœ‰åº“å­˜çš„å¯å”®ç±»å‹
    frog_types = fetch_frog_types()
    saleable = [(c, d) for c, d in frog_types if c.startswith(("SP_", "ZB_", "SY_"))]
    available_types = [(c, d) for c, d in saleable if inventory_dict.get(c, 0) > 0]
    if not available_types:
        st.warning("è¯¥æ± åŒºæ— å¯é”€å”®è›™ç±»")
        st.caption("å½“å‰åº“å­˜è¯¦æƒ…ï¼š")
        for code, desc, qty in inventory:
            st.caption(f"- {desc}: {int(qty)} åª")
        return

    with st.form(key=f"sale_form_{pool_area}"):
        col1, col2 = st.columns(2)
        with col1:
            opts = [f"{c} - {d}" for c, d in available_types]
            sel = st.selectbox("æˆè›™ç±»å‹", opts, key=f"frog_type_select_{pool_area}")
            selected_frog_type = sel.split(" - ")[0]
            current_stock = inventory_dict[selected_frog_type]
            st.caption(f"ğŸ“Œ å½“å‰åº“å­˜ï¼š**{int(current_stock)} åª**")
            qty = st.number_input("é”€å”®æ•°é‡", min_value=1,
                                  max_value=int(current_stock),
                                  key=f"sale_qty_{pool_area}")
            unit_price = st.number_input("å•ä»·ï¼ˆå…ƒ/åªï¼‰", min_value=0.0, value=0.0,
                                         key=f"unit_price_{pool_area}")
        with col2:
            dt = st.date_input("é”€å”®æ—¥æœŸ", datetime.now(), key=f"sale_date_{pool_area}")
            tm = st.time_input("é”€å”®æ—¶é—´", datetime.now().time(), key=f"sale_time_{pool_area}")
            customer = st.text_input("å®¢æˆ·", key=f"customer_{pool_area}")
            remarks = st.text_area("å¤‡æ³¨", placeholder="å¦‚ï¼šå®¢æˆ·ç‰¹æ®Šè¦æ±‚ã€è¿è¾“æ–¹å¼ç­‰",
                                   key=f"remarks_{pool_area}")

        uploaded_files = st.file_uploader(
            "ğŸ“¸ ä¸Šä¼ é”€å”®å‡­è¯ï¼ˆå¯å¤šé€‰ï¼‰",
            type=["jpg", "jpeg", "png", "mp4", "mov"],
            accept_multiple_files=True,
            key=f"media_sale_{pool_area}"
        )

        submitted = st.form_submit_button("é”€å”®")
        if submitted:
            if not customer.strip():
                st.error("è¯·è¾“å…¥å®¢æˆ·")
            elif qty > current_stock:
                st.error(f"é”€å”®æ•°é‡è¶…è¿‡åº“å­˜ï¼å½“å‰æœ€å¤šå¯å”® {int(current_stock)} åª")
            else:
                sale_remarks = f"ä» {pool_area} é”€å”®ç»™ {customer}"
                if unit_price > 0:
                    total_amount = qty * unit_price
                    sale_remarks += f"ï¼Œå•ä»·{unit_price}å…ƒï¼Œæ€»é‡‘é¢{total_amount}å…ƒ"
                if remarks.strip():
                    sale_remarks += f"ã€‚å¤‡æ³¨ï¼š{remarks}"
                ok, msg = record_frog_sale_from_pool(
                    selected_frog_type, qty,
                    datetime.combine(dt, tm),
                    operator.strip(),
                    pool_area,
                    remarks=sale_remarks,
                    media_files=uploaded_files
                )
                if ok:
                    st.success(msg)
                    # æ¸…ç¼“å­˜
                    get_pool_frog_inventory.clear()
                    get_frog_inventory_data.clear()
                    get_sales_statistics.clear()
                    get_sales_data.clear()
                    st.rerun()
                else:
                    st.error(msg)
# ----------------------------- åˆ†ææ¨¡å—ï¼ˆä¿æŒä¸å˜ï¼‰----------------------------- #
def render_analysis_module():
    st.header("æ•°æ®åˆ†æä¸æŸ¥è¯¢")
    st.markdown("---")
    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input("å¼€å§‹æ—¥æœŸ", datetime.now() - timedelta(days=30), key="a_start")
    with col2:
        end_date = st.date_input("ç»“æŸæ—¥æœŸ", datetime.now() + timedelta(days=365), key="a_end")  # åŒ…å«æœªæ¥
    start_dt = datetime.combine(start_date, datetime.min.time())
    end_dt = datetime.combine(end_date, datetime.max.time())
    # æ‰¹æ¬¡è½¬åŒ–ç‡
    with st.expander("1. æ‰¹æ¬¡è½¬åŒ–ç‡åˆ†æ", expanded=False):
        df = get_batch_conversion_data(start_dt, end_dt)
        if not df.empty:
            st.dataframe(df.rename(columns={
                'batch_no': 'æ‰¹æ¬¡å·', 'pool_no': 'å­µåŒ–æ± ç¼–å·', 'input_type': 'æŠ•å…¥ç±»å‹',
                'initial_input': 'åˆå§‹æŠ•å…¥é‡', 'input_unit': 'æŠ•å…¥å•ä½', 'input_date': 'æŠ•å…¥æ—¥æœŸ',
                'total_sorted_frog': 'ç´¯è®¡åˆ†æ‹£æˆè›™', 'conversion_rate': 'è½¬åŒ–ç‡(%)', 'batch_status': 'æ‰¹æ¬¡çŠ¶æ€'
            }))
            fig = px.bar(df, x='batch_no', y='conversion_rate', color='input_type', title='å„æ‰¹æ¬¡è½¬åŒ–ç‡')
            st.plotly_chart(fig, use_container_width=True)
    # æˆè›™åº“å­˜
    with st.expander("3. æˆè›™åº“å­˜åˆ†æ", expanded=False):
        df = get_frog_inventory_data()
        if not df.empty:
            st.dataframe(df.rename(columns={
                'frog_type_code': 'ç±»å‹ä»£ç ', 'frog_type': 'ç±»å‹', 'quantity': 'æ•°é‡', 'pool_area': 'æ± åŒº'
            }))
            fig = px.bar(df, x='frog_type', y='quantity', color='pool_area', title='åº“å­˜åˆ†å¸ƒ')
            st.plotly_chart(fig, use_container_width=True)
    # é”€å”®åˆ†æ
    with st.expander("4. é”€å”®åˆ†æ", expanded=False):
        if st.button("ğŸ”„ åˆ·æ–°é”€å”®æ•°æ®", key="refresh_sales"):
            get_sales_data.clear()
            st.rerun()
        df = get_sales_data(start_dt, end_dt)
        if df.empty:
            st.info("åœ¨æ‰€é€‰æ—¶é—´æ®µå†…æ— é”€å”®è®°å½•")
        else:
            def extract_source(remark):
                if pd.isna(remark) or not isinstance(remark, str) or 'æ¥è‡ª' not in remark:
                    return 'æœªçŸ¥'
                parts = remark.split(' ')
                return parts[1] if len(parts) > 1 else 'æœªçŸ¥'
            df['æ¥æº'] = df['remarks'].apply(extract_source)
            st.dataframe(df.rename(columns={
                'frog_type_code': 'è›™ç±»å‹ä»£ç ',
                'frog_type': 'è›™ç±»å‹',
                'total_sold': 'é”€å”®æ•°é‡',
                'sale_date': 'é”€å”®æ—¥æœŸ',
                'remarks': 'å¤‡æ³¨',
                'æ¥æº': 'æ¥æºæ± åŒº'
            }), use_container_width=True)
            fig = px.pie(df, values='total_sold', names='æ¥æº', title='å„æ¥æºé”€å”®å æ¯”')
            st.plotly_chart(fig, use_container_width=True)
    # å­µåŒ–æ± çŠ¶æ€
    with st.expander("5. å­µåŒ–æ± çŠ¶æ€", expanded=False):
        pools = fetch_incubation_pools()
        if pools:
            df = pd.DataFrame(pools, columns=['æ± å·', 'ä½ç½®', 'çŠ¶æ€', 'æ‰¹æ¬¡'])
            st.dataframe(df)
            status_counts = df['çŠ¶æ€'].value_counts().reset_index()
            status_counts.columns = ['çŠ¶æ€', 'æ•°é‡']
            fig_pie = px.pie(
                status_counts,
                values='æ•°é‡',
                names='çŠ¶æ€',
                title='å­µåŒ–æ± çŠ¶æ€åˆ†å¸ƒ',
                color_discrete_sequence=px.colors.qualitative.Set3
            )
            st.plotly_chart(fig_pie, use_container_width=True)
            fig_bar = px.bar(
                status_counts,
                x='çŠ¶æ€',
                y='æ•°é‡',
                title='å„çŠ¶æ€æ± å­æ•°é‡',
                text='æ•°é‡',
                color='çŠ¶æ€',
                color_discrete_sequence=px.colors.qualitative.Pastel
            )
            fig_bar.update_traces(textposition='outside')
            st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.info("æš‚æ— å­µåŒ–æ± æ•°æ®")
def render_pool_detail_module():
    st.header("æ± åŒºåº“å­˜è¯¦æƒ…")
    st.markdown("æŸ¥çœ‹å„é€»è¾‘æ± åŒºï¼ˆå¦‚ `è‡ªå…»åµ-ç»†çš®æˆè›™æ± `ï¼‰çš„å®æ—¶åº“å­˜åˆ†å¸ƒ")
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
        get_frog_inventory_data.clear()
        st.rerun()
    df = get_frog_inventory_data()
    if df.empty:
        st.info("æš‚æ— åº“å­˜æ•°æ®")
        return
    def parse_pool_area(pool):
        if pool in ["ç§è›™æ± ", "è¯•éªŒè›™æ± ", "å•†å“è›™æ± "]:
            return "é€šç”¨", pool
        elif "-" in pool:
            parts = pool.split("-", 1)
            source = parts[0]
            stage = parts[1]
            return source, stage
        else:
            return "æœªçŸ¥", pool
    df[['æ¥æº', 'é˜¶æ®µ']] = df['pool_area'].apply(lambda x: pd.Series(parse_pool_area(x)))
    col1, col2 = st.columns(2)
    with col1:
        sources = ["å…¨éƒ¨"] + sorted(df['æ¥æº'].unique().tolist())
        selected_source = st.selectbox("æŒ‰æ¥æºç­›é€‰", sources)
    with col2:
        stages = ["å…¨éƒ¨"] + sorted(df['é˜¶æ®µ'].unique().tolist())
        selected_stage = st.selectbox("æŒ‰é˜¶æ®µç­›é€‰", stages)
    filtered_df = df.copy()
    if selected_source != "å…¨éƒ¨":
        filtered_df = filtered_df[filtered_df['æ¥æº'] == selected_source]
    if selected_stage != "å…¨éƒ¨":
        filtered_df = filtered_df[filtered_df['é˜¶æ®µ'] == selected_stage]
    if filtered_df.empty:
        st.warning("æ— åŒ¹é…æ•°æ®")
        return
    for pool in filtered_df['pool_area'].unique():
        pool_data = filtered_df[filtered_df['pool_area'] == pool]
        total_qty = pool_data['quantity'].sum()
        last_update = pool_data['last_update_time'].max()
        with st.expander(f"ğŸ“ {pool} ï¼ˆæ€»è®¡ï¼š{int(total_qty)} åªï¼Œæœ€åæ›´æ–°ï¼š{last_update.strftime('%Y-%m-%d %H:%M') if pd.notna(last_update) else 'N/A'}ï¼‰", expanded=False):
            st.dataframe(
                pool_data[['frog_type', 'quantity']].rename(columns={
                    'frog_type': 'è›™ç±»å‹',
                    'quantity': 'æ•°é‡ï¼ˆåªï¼‰'
                }),
                use_container_width=True,
                hide_index=True
            )
def render_inventory_module():
    st.header("ğŸ“¦ è¿›é”€å­˜ç®¡ç†ï¼ˆç‹¬ç«‹æ¨¡å¼ï¼‰")
    st.markdown("æ‰‹åŠ¨å½•å…¥ç‰©èµ„æˆ–è›™ç±»çš„å…¥åº“ã€å‡ºåº“ã€ç›˜ç‚¹ï¼Œä¸ä¾èµ–å…»æ®–æµç¨‹")
    operator = st.text_input("æ“ä½œå‘˜", value="admin", key="inv_operator")
    if not operator.strip():
        st.warning("è¯·è¾“å…¥æ“ä½œå‘˜")
        return
    obj_type = st.radio("æ“ä½œå¯¹è±¡", ["ğŸ¸ è›™ç±»", "ğŸ“¦ ç‰©èµ„"], horizontal=True)
    if obj_type == "ğŸ¸ è›™ç±»":
        types = fetch_frog_types()
        type_options = [f"{c} - {d}" for c, d in types if c.startswith(("SP_", "ZB_", "SY_"))]
        item_label = "è›™ç±»å‹"
        pool_label = "æ± åŒºï¼ˆå¯é€‰ï¼‰"
    else:
        types = fetch_material_types()
        type_options = [f"{c} - {d} ({u})" for c, d, u in types]
        item_label = "ç‰©èµ„ç±»å‹"
        pool_label = "ä»“åº“ï¼ˆå¯é€‰ï¼‰"
    if not type_options:
        st.warning(f"æœªå®šä¹‰{item_label}")
        return
    with st.form("inventory_form"):
        col1, col2 = st.columns(2)
        with col1:
            selected = st.selectbox(item_label, type_options)
            item_code = selected.split(" - ")[0]
            operation = st.selectbox("æ“ä½œç±»å‹", ["å…¥åº“", "å‡ºåº“", "ç›˜ç‚¹"])
            quantity = st.number_input("æ•°é‡", min_value=0.01, step=0.1)
        with col2:
            pool_or_warehouse = st.text_input(pool_label, placeholder="å¦‚ï¼šè‡ªå…»åµ-å•†å“è›™æ±  æˆ– é¥²æ–™ä»“")
            dt = st.date_input("æ—¥æœŸ", datetime.now())
            tm = st.time_input("æ—¶é—´", datetime.now().time())
            remarks = st.text_area("å¤‡æ³¨")
        submitted = st.form_submit_button("æäº¤è®°å½•")
        if submitted:
            item_type = "frog" if obj_type == "ğŸ¸ è›™ç±»" else "material"
            ok, msg = record_inventory_operation(
                item_type=item_type,
                item_code=item_code,
                operation=operation,
                quantity=quantity,
                pool_or_warehouse=pool_or_warehouse,
                operation_time=datetime.combine(dt, tm),
                operator=operator.strip(),
                remarks=remarks
            )
            if ok:
                st.success(msg)
                st.rerun()
            else:
                st.error(msg)
    st.markdown("---")
    st.subheader("å½“å‰åº“å­˜")
    if st.button("ğŸ”„ åˆ·æ–°åº“å­˜"):
        get_frog_inventory_data.clear()
    frog_df = get_frog_inventory_data()
    if not frog_df.empty:
        st.write("ğŸ¸ è›™ç±»åº“å­˜")
        st.dataframe(frog_df.rename(columns={
            'frog_type_code': 'ç±»å‹ä»£ç ', 'frog_type': 'åç§°', 'quantity': 'æ•°é‡', 'pool_area': 'æ± åŒº'
        }), use_container_width=True)
    with DatabaseConnection() as conn:
        if conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT m.type_code, m.name, m.unit, i.remaining_quantity
                    FROM t_material_inventory i
                    JOIN t_material_type_dict m ON i.material_type_code = m.type_code
                    ORDER BY m.name
                """)
                mats = cur.fetchall()
                if mats:
                    mat_df = pd.DataFrame(mats, columns=['ç±»å‹ä»£ç ', 'åç§°', 'å•ä½', 'æ•°é‡'])
                    st.write("ğŸ“¦ ç‰©èµ„åº“å­˜")
                    st.dataframe(mat_df, use_container_width=True)
# ----------------------------- ä¸»å…¥å£ ----------------------------- #
def run():
    st.set_page_config(page_title="çŸ³è›™å…»æ®–ç®¡ç†ç³»ç»Ÿ", page_icon="ğŸ¸", layout="wide")
    st.title("ğŸ¸ çŸ³è›™å…»æ®–ç®¡ç†ç³»ç»Ÿï¼ˆå››æ¥æºåˆ†ç¦»ç‰ˆï¼‰")
    if 'db_initialized' not in st.session_state:
        required_tables = ['t_incubation_pool', 't_frog_type_dict', 't_material_type_dict', 't_incubation_batch', 't_batch_sorting_record']
        try:
            with DatabaseConnection() as conn:
                if not conn: st.error("æ•°æ®åº“è¿æ¥å¤±è´¥"); st.stop()
                with conn.cursor() as cur:
                    for tbl in required_tables:
                        cur.execute("SELECT 1 FROM information_schema.tables WHERE table_name = %s", (tbl,))
                        if not cur.fetchone():
                            st.error(f"å¿…è¦è¡¨ {tbl} ä¸å­˜åœ¨"); st.stop()
            st.session_state['db_initialized'] = True
        except Exception as e:
            st.error(f"æ£€æŸ¥è¡¨å¤±è´¥: {e}"); st.stop()
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ç°åœºæ“ä½œè®°å½•", 
        "æ•°æ®åˆ†æä¸æŸ¥è¯¢", 
        "ğŸ“Š æ± åŒºè¯¦æƒ…",
        "ğŸ“¦ è¿›é”€å­˜ç®¡ç†",
        "ğŸ” å¤šåª’ä½“æº¯æº"
    ])
    with tab1: render_operation_module()
    with tab2: render_analysis_module()
    with tab3: render_pool_detail_module()
    with tab4: render_inventory_module() 
    with tab5: render_media_traceability()
if __name__ == "__main__":
    run()