# chatbot.py - AI èŠå¤©åŠ©æ‰‹ï¼ˆåŒè¯­æ”¯æŒï¼‰
import os
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆé˜¿é‡Œäº‘ç™¾ç‚¼ï¼‰
@st.cache_resource
def get_client():
    return OpenAI(
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )


def render(t):
    """
    ä¸»å…¥å£å‡½æ•°
    :param t: ç¿»è¯‘å‡½æ•°ï¼Œt(key) -> str
    """
    st.title(t("chatbot_title"))
    st.markdown(f"""
    ### {t("chatbot_description")}

    I'm the AI assistant from **Habitats Studio**. I can help you with:
    
    - {t("chatbot_service_1")}
    - {t("chatbot_service_2")}
    - {t("chatbot_service_3")}
    - {t("chatbot_service_4")}

    {t("chatbot_instruction")}
    """)
    st.markdown("---")

    client = get_client()

    # åˆå§‹åŒ– session_state ä¸­çš„æ¶ˆæ¯å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {
                "role": "system",
                "content": """You are a helpful, professional AI assistant for Habitat Studio, a data analytics consultancy.
                - Always reply in the SAME LANGUAGE as the user's latest message.
                - If the user uses Chinese, reply in Chinese. If English, reply in English. Support mixed input.
                - Be concise, friendly, and informative.
                - For collaboration requests, suggest they visit the Contact page.
                - Do not use markdown formatting in your responses."""
            },
            {
                "role": "assistant",
                "content": t("chatbot_welcome")  # å¤šè¯­è¨€æ¬¢è¿è¯­ï¼ˆAI ä¼šè‡ªåŠ¨é€‚é…ï¼‰
            }
        ]

    # æ˜¾ç¤ºèŠå¤©å†å²
    for msg in st.session_state.messages:
        if msg["role"] == "assistant":
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.write(msg["content"])
        elif msg["role"] == "user":
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.write(msg["content"])

    # ç”¨æˆ·è¾“å…¥æ¡†
    prompt = st.chat_input(t("chatbot_input"))
    if prompt:
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.write(prompt)

        # æ·»åŠ åˆ°å†å²
        st.session_state.messages.append({"role": "user", "content": prompt})

        try:
            stream = client.chat.completions.create(
                model="qwen-plus",
                messages=st.session_state.messages,
                stream=True
            )

            # æµå¼è¾“å‡º
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                response = st.write_stream(stream)

            st.session_state.messages.append({"role": "assistant", "content": response})

        except Exception as e:
            st.error(t("chatbot_error").format(error=str(e)))
            st.info(t("chatbot_check"))

    # æ¸…é™¤å¯¹è¯æŒ‰é’®
    st.markdown("---")
    if st.button(t("chatbot_clear")):
        st.session_state.messages = st.session_state.messages[:1]  # ä¿ç•™ system æ¶ˆæ¯
        st.rerun()